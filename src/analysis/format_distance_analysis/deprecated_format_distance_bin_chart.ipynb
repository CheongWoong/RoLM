{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT_TYPE_MAP = {\n",
    "    \"0\": {\"separator\": \":\", \"casing\": \"capitalize\", \"space\": \"\"},\n",
    "    \"1\": {\"separator\": \":\", \"casing\": \"capitalize\", \"space\": \" \"},\n",
    "    \"2\": {\"separator\": \":\", \"casing\": \"upper\", \"space\": \"\"},\n",
    "    \"3\": {\"separator\": \":\", \"casing\": \"upper\", \"space\": \" \"},\n",
    "    \"4\": {\"separator\": \": \", \"casing\": \"capitalize\", \"space\": \"\"},\n",
    "    \"5\": {\"separator\": \": \", \"casing\": \"capitalize\", \"space\": \" \"},\n",
    "    \"6\": {\"separator\": \": \", \"casing\": \"upper\", \"space\": \"\"},\n",
    "    \"7\": {\"separator\": \": \", \"casing\": \"upper\", \"space\": \" \"},\n",
    "}\n",
    "format_config = {\n",
    "    \"0\": [0,0,0],\n",
    "    \"1\": [0,0,1],\n",
    "    \"2\": [0,1,0],\n",
    "    \"3\": [0,1,1],\n",
    "    \"4\": [1,0,0],\n",
    "    \"5\": [1,0,1],\n",
    "    \"6\": [1,1,0],\n",
    "    \"7\": [1,1,1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_configs(format_factor_number):\n",
    "    num_formats = pow(2, format_factor_number)\n",
    "    assert num_formats == NUM_FORMATS\n",
    "    return [f\"{i}_{j}\" for i in range(num_formats) for j in range(num_formats) if i < j]\n",
    "\n",
    "def get_format_distance(f1, f2):\n",
    "    f1 = format_config[f1]\n",
    "    f2 = format_config[f2]\n",
    "    return sum([abs(f1[i] - f2[i]) for i in range(format_num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with consistency (bin chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"bin_chart\", exist_ok=True)\n",
    "\n",
    "dataset_names = [\"CommonsenseQA\", \"QASC\", \"100TFQA\", \"GSM8K\"]\n",
    "model_names = [\"Phi-3.5-mini-instruct\", \"Phi-3.5-vision-instruct\", \"Llama-3.1-8B\", \"Llama-3.1-8B-Instruct\", \"DeepSeek-R1-Distill-Llama-8B\", \"gpt-4o-2024-11-20\"]\n",
    "prompting_strategies = [\"zero-shot\", \"zero-shot-cot\", \"few-shot\", \"few-shot-cot\"]\n",
    "NUM_FORMATS = 8\n",
    "format_num = 3\n",
    "\n",
    "# Read score file\n",
    "scores = {}\n",
    "for model_name in model_names:\n",
    "    for dataset_name in dataset_names:\n",
    "        for prompting_strategy in prompting_strategies:\n",
    "            input_path = f\"{result_dir}/{dataset_name}/{model_name}/{prompting_strategy}_score.json\"\n",
    "            try:\n",
    "                with open(input_path) as fin:\n",
    "                    score = json.load(fin)\n",
    "                    scores[(model_name, dataset_name, prompting_strategy)] = score\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                continue\n",
    "\n",
    "pairwise_distance = {k : get_format_distance(k[0], k[2]) for k in get_configs(format_num)}\n",
    "\n",
    "for m_i, model_name in enumerate(model_names):\n",
    "    fig, axes = plt.subplots(nrows=len(dataset_names), ncols=len(prompting_strategies), figsize=(20, 20))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    for d_j, dataset_name in enumerate(dataset_names):\n",
    "        for p_k, prompting_strategy in enumerate(prompting_strategies):\n",
    "            try:\n",
    "                score = scores[(model_name, dataset_name, prompting_strategy)]\n",
    "            except:\n",
    "                continue\n",
    "            # Bar\n",
    "            dist_consistency = defaultdict(list)\n",
    "            for k, v in pairwise_distance.items():\n",
    "                dist_consistency[v].append(score[\"consistency\"][k])\n",
    "\n",
    "            y_vals = []\n",
    "            y_errs = []\n",
    "            for k, v in dist_consistency.items():\n",
    "                mean = sum(v) / len(v)\n",
    "                std = (sum([(x - mean) ** 2 for x in v]) / len(v)) ** 0.5\n",
    "\n",
    "                y_vals.append(mean)\n",
    "                y_errs.append(std)\n",
    "                \n",
    "            x_vals = [i+1 for i in range(format_num)]\n",
    "            max_vals = [x + y for x, y in zip(y_vals, y_errs)]\n",
    "\n",
    "            axes[d_j, p_k].bar(x_vals, y_vals, yerr=y_errs, capsize=5, color=\"mediumpurple\")\n",
    "            axes[d_j, p_k].set_title(f\"{dataset_name} - {prompting_strategy}\")\n",
    "            axes[d_j, p_k].set_xlabel(\"Format Distance\")\n",
    "            axes[d_j, p_k].set_ylabel(\"Consistency\")\n",
    "            axes[d_j, p_k].set_xticks(x_vals)\n",
    "            y_ticks = [0.3, 0.35, 0.4, 0.45, 0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0]\n",
    "            axes[d_j, p_k].set_yticks(y_ticks)\n",
    "            axes[d_j, p_k].set_ylim(0.45, 1.0)\n",
    "            # if max(max_vals) > 0.95:\n",
    "            #     axes[d_j, p_k].set_ylim(min(min(y_vals) - 0.1, 0.84), 1.00)\n",
    "            # else:\n",
    "            #     axes[d_j, p_k].set_ylim(min(min(y_vals) - 0.1, 0.84), min(max(y_vals) + 0.1, 1.0))\n",
    "            axes[d_j, p_k].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    # fig.suptitle(f\"{model_name} : Consistency Across Format Distances\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"bin_chart/format-distance_{model_name}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended analysis with 128 formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FORMATS = 128\n",
    "FORMAT_ELE_NUM = 7\n",
    "\n",
    "def get_configs(format_ele_num):\n",
    "    num_formats = pow(2, format_ele_num)\n",
    "    assert num_formats == NUM_FORMATS\n",
    "    return [f\"{i}_{j}\" for i in range(num_formats) for j in range(num_formats) if i < j]\n",
    "\n",
    "def get_format_distance(f1, f2, format_num=FORMAT_ELE_NUM):\n",
    "    a = list(f\"{f1:07b}\")\n",
    "    b = list(f\"{f2:07b}\")\n",
    "    dis = format_num*hamming(a, b)\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"bin_chart\", exist_ok=True)\n",
    "\n",
    "dataset_names = [\"CommonsenseQA\", \"QASC\"]\n",
    "model_names = [\"Llama-3.1-8B-Instruct\"]\n",
    "prompting_strategies = [\"zero-shot\"]\n",
    "\n",
    "# Read score file\n",
    "scores = {}\n",
    "for model_name in model_names:\n",
    "    for dataset_name in dataset_names:\n",
    "        for prompting_strategy in prompting_strategies:\n",
    "            input_path = f\"{result_dir}/{dataset_name}/{model_name}/{prompting_strategy}_ext_score.json\"\n",
    "            try:\n",
    "                with open(input_path) as fin:\n",
    "                    score = json.load(fin)\n",
    "                    scores[(model_name, dataset_name, prompting_strategy)] = score\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                continue\n",
    "\n",
    "pairwise_distance = {k : get_format_distance(int(k.split(\"_\")[0]), int(k.split(\"_\")[1])) for k in get_configs(FORMAT_ELE_NUM)}\n",
    "\n",
    "for m_i, model_name in enumerate(model_names):\n",
    "    for d_j, dataset_name in enumerate(dataset_names):\n",
    "        for p_k, prompting_strategy in enumerate(prompting_strategies):\n",
    "            try:\n",
    "                score = scores[(model_name, dataset_name, prompting_strategy)]\n",
    "            except:\n",
    "                continue\n",
    "            # Bar\n",
    "            dist_consistency = defaultdict(list)\n",
    "            for k, v in pairwise_distance.items():\n",
    "                dist_consistency[v].append(score[\"consistency\"][k])\n",
    "\n",
    "            y_vals = []\n",
    "            y_errs = []\n",
    "            for k, v in dist_consistency.items():\n",
    "                mean = sum(v) / len(v)\n",
    "                std = (sum([(x - mean) ** 2 for x in v]) / len(v)) ** 0.5\n",
    "\n",
    "                y_vals.append(mean)\n",
    "                y_errs.append(std)\n",
    "\n",
    "            x_vals = [i+1 for i in range(FORMAT_ELE_NUM)]\n",
    "            # with open(os.path.join(current_dir, f\"..//accum.jsonl\"), \"a\") as fout:\n",
    "            #     json.dump({\"model_name\": model_name, \"dataset_name\": dataset_name, \"prompting_strategy\": prompting_strategy, \"x_vals\": x_vals, \"y_vals\": y_vals, \"y_err\": y_errs,\"y_lists\": dist_consistency}, fout)\n",
    "            #     fout.write(\"\\n\")\n",
    "            \n",
    "\n",
    "            # Plot settings\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            # plt.scatter(x_vals, y_vals, s=100, c=\"blue\", alpha=0.5)    \n",
    "            # plt.bar(x_vals, y_vals, yerr=y_errs, capsize=5, color=\"mediumpurple\")\n",
    "            plt.bar(x_vals, y_vals, yerr=y_errs, capsize=5, color=\"mediumpurple\")\n",
    "            plt.xlabel(\"Format Distance\")\n",
    "            plt.ylabel(\"Consistency\")\n",
    "            plt.xticks(x_vals)\n",
    "            ticks = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "            ticks = [0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1]\n",
    "            plt.yticks(ticks)\n",
    "            plt.ylim(0.9, 1)\n",
    "            # plt.ylim(0.95, 1)\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "            plt.title(f\"Consistency Across Format Distances-{model_name}-{dataset_name} ({prompting_strategy})\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            mn = \"R1\" if \"R1\" in model_name else \"Llama-Instruct\" if \"Llama-3.1-8B-Instruct\" in model_name else \"Llama-Base\" if \"Llama-3.1-8B\" in model_name else \"Phi-mini\" if \"Phi-3.5-mini-instruct\" in model_name else \"Phi-vision\" if \"Phi-3.5-vision-instruct\" in model_name else \"Gpt\" if \"gpt\" in model_name else None\n",
    "            dn = \"CQA\" if \"Commonsense\" in dataset_name else dataset_name\n",
    "            shots = \"zs\" if \"zero\" in prompting_strategy else \"fs\" if \"few\" in prompting_strategy else None\n",
    "            strategy = \"\"\n",
    "            strategy += \"-cot\" if \"cot\" in prompting_strategy else \"\"\n",
    "            strategy += \"-com\" if \"com\" in prompting_strategy else \"\"\n",
    "            strategy += \"-rar\" if \"rar\" in prompting_strategy else \"\"\n",
    "            strategy += \"-ref\" if \"ref\" in prompting_strategy else \"\"\n",
    "            strategy += \"-guided\" if \"guided\" in prompting_strategy else \"\"\n",
    "\n",
    "            ps = shots + strategy\n",
    "            plt.savefig(f\"bin_chart/EXformat_distance-{dn}_{mn}_{ps}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
