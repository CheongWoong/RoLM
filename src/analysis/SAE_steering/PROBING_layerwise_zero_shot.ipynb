{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "\n",
    "from itertools import combinations\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_memmap(filepath):\n",
    "    with open(filepath.replace(\".dat\", \".conf\"), \"r\") as fin_config:\n",
    "        memmap_configs = json.load(fin_config)\n",
    "        return np.memmap(filepath, mode=\"r\", shape=tuple(memmap_configs[\"shape\"]), dtype=memmap_configs[\"dtype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FORMATS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\"\n",
    "input_dir = \"../../../preprocessed_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-3.1-8B-Instruct\"\n",
    "dataset_name = \"CommonsenseQA\"\n",
    "prompting_strategy = \"zero-shot\"\n",
    "\n",
    "id_predictions_map = {}\n",
    "\n",
    "output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "\n",
    "predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_predictions_validation.jsonl\")\n",
    "try:\n",
    "    with jsonlines.open(predictions_path) as fin:\n",
    "        id_predictions_map = {}\n",
    "        for example in fin.iter():\n",
    "            id_predictions_map[example[\"id\"]] = example[\"predictions\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "labels = []\n",
    "for preds in id_predictions_map.values():\n",
    "    pairwise_labels = []\n",
    "    for i, j in list(combinations(range(8), 2)):\n",
    "        label = int(preds[str(i)] == preds[str(j)])\n",
    "        pairwise_labels.append(label)\n",
    "    labels.append(pairwise_labels)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_pairwise_embeddings(hidden_states):\n",
    "    num_samples = hidden_states.shape[0]\n",
    "\n",
    "    pairwise_embeddings = []\n",
    "\n",
    "    for s in range(num_samples):\n",
    "        sample_pairs = []\n",
    "        for i, j in list(combinations(range(8), 2)):\n",
    "            emb_i = hidden_states[s, i]\n",
    "            emb_j = hidden_states[s, j]\n",
    "            concat = np.concatenate([emb_i, emb_j], axis=-1)\n",
    "            sample_pairs.append(concat)\n",
    "        sample_pairs = np.stack(sample_pairs, axis=0)\n",
    "        pairwise_embeddings.append(sample_pairs)\n",
    "\n",
    "    return np.stack(pairwise_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_layer_wise_hidden_states_validation.dat\")\n",
    "head_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_head_wise_hidden_states_validation.dat\")\n",
    "\n",
    "layer_wise_hidden_states = read_memmap(layer_wise_path)\n",
    "head_wise_hidden_states = read_memmap(head_wise_path)\n",
    "\n",
    "pairwise_layer_wise_hidden_states = expand_pairwise_embeddings(layer_wise_hidden_states)\n",
    "pairwise_head_wise_hidden_states = expand_pairwise_embeddings(head_wise_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.81      0.84      0.82      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  28   12]\n",
      " [  17 1310]]\n",
      "[0.843594574227581]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.81      0.84      0.83      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  28   12]\n",
      " [  16 1311]]\n",
      "[0.843594574227581, 0.8439713639788997]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.87      0.85      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  30   10]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.86      0.84      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  29   11]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.85      0.88      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  31    9]\n",
      " [  13 1314]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.85      0.84      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  28   12]\n",
      " [  13 1314]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.84      0.84      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  28   12]\n",
      " [  14 1313]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.85      0.84      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  28   12]\n",
      " [  13 1314]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.81      0.83      0.82      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  27   13]\n",
      " [  16 1311]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.85      0.87      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  30   10]\n",
      " [  13 1314]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.82      0.87      0.84      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  30   10]\n",
      " [  17 1310]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.70        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.82      0.88      0.85      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  31    9]\n",
      " [  17 1310]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.81      0.87      0.84      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  30   10]\n",
      " [  18 1309]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.88      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  31    9]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.81      0.87      0.84      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  30   10]\n",
      " [  18 1309]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.70        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.82      0.88      0.85      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  31    9]\n",
      " [  17 1310]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.82      0.89      0.85      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  17 1310]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.89      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.89      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  16 1311]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.82      0.89      0.85      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  17 1310]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.88      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  31    9]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.88      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  31    9]\n",
      " [  14 1313]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.88      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  31    9]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.89      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  16 1311]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.89      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  16 1311]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998, 0.8939713639788998]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.89      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  16 1311]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.89      0.87      1367\n",
      "weighted avg       0.99      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  14 1313]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998, 0.8947249434815373]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.89      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998, 0.8947249434815373, 0.8943481537302186]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.89      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998, 0.8947249434815373, 0.8943481537302186, 0.8943481537302186]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.91      0.87      1367\n",
      "weighted avg       0.99      0.98      0.98      1367\n",
      "\n",
      "[[  33    7]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998, 0.8947249434815373, 0.8943481537302186, 0.8943481537302186, 0.9068481537302185]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.78      0.71        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.83      0.88      0.85      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  31    9]\n",
      " [  16 1311]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998, 0.8947249434815373, 0.8943481537302186, 0.8943481537302186, 0.9068481537302185, 0.8814713639788998]\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74        40\n",
      "           1       0.99      0.99      0.99      1327\n",
      "\n",
      "    accuracy                           0.98      1367\n",
      "   macro avg       0.84      0.89      0.86      1367\n",
      "weighted avg       0.98      0.98      0.98      1367\n",
      "\n",
      "[[  32    8]\n",
      " [  15 1312]]\n",
      "[0.843594574227581, 0.8439713639788997, 0.8693481537302186, 0.8568481537302186, 0.8826017332328561, 0.8451017332328561, 0.8447249434815373, 0.8451017332328561, 0.8314713639788998, 0.870101733232856, 0.868594574227581, 0.8810945742275811, 0.8682177844762622, 0.8818481537302185, 0.8682177844762622, 0.8810945742275811, 0.893594574227581, 0.8943481537302186, 0.8939713639788998, 0.893594574227581, 0.8818481537302185, 0.8822249434815372, 0.8818481537302185, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998, 0.8947249434815373, 0.8943481537302186, 0.8943481537302186, 0.9068481537302185, 0.8814713639788998, 0.8943481537302186]\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "num_samples, num_formats, num_layers, hidden_size = layer_wise_hidden_states.shape\n",
    "num_samples, num_formats, num_layers, num_heads, hidden_size2 = head_wise_hidden_states.shape\n",
    "\n",
    "layer_accuracy_scores = []\n",
    "for layer_idx in range(num_layers):\n",
    "    # if layer_idx not in [31]:\n",
    "    #     continue\n",
    "\n",
    "    # Step 1: Prepare input\n",
    "    X = pairwise_layer_wise_hidden_states[:,:,layer_idx,:]\n",
    "    X = X.reshape(-1, hidden_size*2)\n",
    "    Y = labels.reshape(-1)\n",
    "\n",
    "    # Step 2: 80:20 split for validation to select top-K components\n",
    "    X_fold1, X_fold2, y_fold1, y_fold2 = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "    for i in range(2):\n",
    "        # Step 3: Standardization\n",
    "        scaler = StandardScaler()\n",
    "        if i == 0:\n",
    "            X_train = scaler.fit_transform(X_fold1)\n",
    "            X_test = scaler.transform(X_fold2)\n",
    "            y_train, y_test = y_fold1, y_fold2\n",
    "        else:\n",
    "            break\n",
    "            X_train = scaler.fit_transform(X_fold2)\n",
    "            X_test = scaler.transform(X_fold1)\n",
    "            y_train, y_test = y_fold2, y_fold1\n",
    "\n",
    "        # Step 4: Train a linear probing model\n",
    "        clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Step 5: Evaluate the model\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        layer_accuracy_scores.append(accuracy)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "    print(layer_accuracy_scores)\n",
    "    print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9068481537302185, 0.8947249434815373, 0.8943481537302186, 0.8943481537302186, 0.8943481537302186, 0.8943481537302186, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998, 0.8939713639788998]\n",
      "\n",
      "[0.8314713639788998, 0.843594574227581, 0.8439713639788997, 0.8447249434815373, 0.8451017332328561, 0.8451017332328561, 0.8568481537302186, 0.8682177844762622, 0.8682177844762622, 0.868594574227581]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(layer_accuracy_scores, reverse=True)[:10])\n",
    "print()\n",
    "print(sorted(layer_accuracy_scores, reverse=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29, 0.9068481537302185),\n",
       " (26, 0.8947249434815373),\n",
       " (28, 0.8943481537302186),\n",
       " (31, 0.8943481537302186),\n",
       " (27, 0.8943481537302186),\n",
       " (17, 0.8943481537302186),\n",
       " (24, 0.8939713639788998),\n",
       " (25, 0.8939713639788998),\n",
       " (18, 0.8939713639788998),\n",
       " (23, 0.8939713639788998),\n",
       " (16, 0.893594574227581),\n",
       " (19, 0.893594574227581),\n",
       " (4, 0.8826017332328561),\n",
       " (21, 0.8822249434815372),\n",
       " (22, 0.8818481537302185),\n",
       " (20, 0.8818481537302185),\n",
       " (13, 0.8818481537302185),\n",
       " (30, 0.8814713639788998),\n",
       " (11, 0.8810945742275811),\n",
       " (15, 0.8810945742275811),\n",
       " (9, 0.870101733232856),\n",
       " (2, 0.8693481537302186),\n",
       " (10, 0.868594574227581),\n",
       " (14, 0.8682177844762622),\n",
       " (12, 0.8682177844762622),\n",
       " (3, 0.8568481537302186),\n",
       " (5, 0.8451017332328561),\n",
       " (7, 0.8451017332328561),\n",
       " (6, 0.8447249434815373),\n",
       " (1, 0.8439713639788997),\n",
       " (0, 0.843594574227581),\n",
       " (8, 0.8314713639788998)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_topk_layers(layer_scores, k=10):\n",
    "    topk_indices = np.argsort(layer_scores)[-k:][::-1]\n",
    "    topk_info = [(idx, layer_scores[idx]) for idx in topk_indices]\n",
    "    return topk_info\n",
    "\n",
    "get_topk_layers(layer_accuracy_scores, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
