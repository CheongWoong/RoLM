{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e2572b",
   "metadata": {},
   "source": [
    "# Single Format Element Consistency Analysis\n",
    "\n",
    "This notebook analyzes the consistency between format pairs that differ by only one formatting element.\n",
    "\n",
    "## Format Analysis Strategy\n",
    "\n",
    "We analyze 8 different formats represented as 3-bit binary numbers:\n",
    "- Format 0: 000, Format 1: 001, Format 2: 010, Format 3: 011\n",
    "- Format 4: 100, Format 5: 101, Format 6: 110, Format 7: 111\n",
    "\n",
    "### Analysis Pairs by Position:\n",
    "- **Last bit effect** (rightmost): (000,001), (010,011), (100,101), (110,111)\n",
    "- **Middle bit effect**: (000,010), (001,011), (100,110), (101,111)\n",
    "- **First bit effect** (leftmost): (000,100), (001,101), (010,110), (011,111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# Import our analysis functions\n",
    "from single_format_element_consistency import (\n",
    "    get_format_pairs_by_position,\n",
    "    analyze_single_element_consistency,\n",
    "    analyze_dataset_model_combination\n",
    ")\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f899957",
   "metadata": {},
   "source": [
    "## 1. Understand Format Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and display format pairs\n",
    "pairs_by_position = get_format_pairs_by_position()\n",
    "\n",
    "print(\"Format pairs that differ by exactly one bit:\\n\")\n",
    "for position, pairs in pairs_by_position.items():\n",
    "    print(f\"{position.replace('_', ' ').title()} effect pairs:\")\n",
    "    for format_1, format_2 in pairs:\n",
    "        print(f\"  ({format_1:03b}, {format_2:03b}) = (Format {format_1}, Format {format_2})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84821c81",
   "metadata": {},
   "source": [
    "## 2. Analyze Sample Data\n",
    "\n",
    "Let's start by analyzing one specific dataset-model combination to understand the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e13c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze the DeepSeek model on 100TFQA with few-shot CoT\n",
    "# sample_results = analyze_dataset_model_combination(\n",
    "#     dataset_name=\"100TFQA\",\n",
    "#     model_name=\"DeepSeek-R1-Distill-Llama-8B\", \n",
    "#     prompting_strategy=\"few-shot-cot\"\n",
    "# )\n",
    "\n",
    "# if sample_results:\n",
    "#     print(\"Sample Analysis Results for 100TFQA/DeepSeek-R1-Distill-Llama-8B/few-shot-cot:\\n\")\n",
    "    \n",
    "#     for position, results in sample_results.items():\n",
    "#         print(f\"{position.replace('_', ' ').title()} Effect:\")\n",
    "#         print(f\"  Overall mean consistency: {results.get('mean', 0.0):.3f}\")\n",
    "        \n",
    "#         for pair, consistency in results.items():\n",
    "#             if pair != \"mean\":\n",
    "#                 print(f\"  Pair {pair}: {consistency:.3f}\")\n",
    "#         print()\n",
    "# else:\n",
    "#     print(\"Could not load sample data. Please check file paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061db544",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Analysis Across All Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2012f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all combinations to analyze\n",
    "dataset_names = [\"100TFQA\", \"CommonsenseQA\", \"GSM8K\", \"QASC\", \"MMLU-Pro-Law-100Q\"]\n",
    "model_names = [\n",
    "    \"DeepSeek-R1-Distill-Llama-8B\", \n",
    "    \"gpt-4o-2024-11-20\",\n",
    "    \"Llama-3.1-8B\",\n",
    "    \"Llama-3.1-8B-Instruct\",\n",
    "    \"Llama-3.1-70B-Instruct\",\n",
    "    \"Phi-3.5-mini-instruct\",\n",
    "    \"Phi-3.5-vision-instruct\"\n",
    "]\n",
    "prompting_strategies = [\"zero-shot\", \"zero-shot-cot\", \"few-shot\", \"few-shot-cot\"]\n",
    "\n",
    "# Collect all results\n",
    "all_results = {}\n",
    "summary_data = []\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for model_name in model_names:\n",
    "        for prompting_strategy in prompting_strategies:\n",
    "            print(f\"Analyzing {dataset_name}/{model_name}/{prompting_strategy}...\")\n",
    "            \n",
    "            results = analyze_dataset_model_combination(\n",
    "                dataset_name, model_name, prompting_strategy\n",
    "            )\n",
    "            \n",
    "            if results is not None:\n",
    "                # Store detailed results\n",
    "                key = f\"{dataset_name}_{model_name}_{prompting_strategy}\"\n",
    "                all_results[key] = results\n",
    "                \n",
    "                # Collect summary data\n",
    "                for position in [\"first_bit\", \"middle_bit\", \"last_bit\"]:\n",
    "                    if position in results:\n",
    "                        summary_data.append({\n",
    "                            \"Dataset\": dataset_name,\n",
    "                            \"Model\": model_name,\n",
    "                            \"Strategy\": prompting_strategy,\n",
    "                            \"Position\": position,\n",
    "                            \"Mean_Consistency\": 1 - results[position][\"mean\"] #.get(\"mean\", 0.0)\n",
    "                        })\n",
    "\n",
    "print(f\"\\nAnalyzed {len(all_results)} combinations.\")\n",
    "print(f\"Collected {len(summary_data)} data points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21dac2",
   "metadata": {},
   "source": [
    "## 4. Summary Statistics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "if summary_data:\n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(\"Summary Statistics by Position:\")\n",
    "    position_stats = df_summary.groupby('Position')['Mean_Consistency'].agg(['mean', 'std', 'min', 'max', 'count'])\n",
    "    print(position_stats)\n",
    "    \n",
    "    print(\"\\nOverall Statistics:\")\n",
    "    print(f\"Overall mean consistency: {df_summary['Mean_Consistency'].mean():.3f}\")\n",
    "    print(f\"Overall standard deviation: {df_summary['Mean_Consistency'].std():.3f}\")\n",
    "else:\n",
    "    print(\"No data collected for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420856d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = {}\n",
    "# Collect all results\n",
    "for dataset_name in dataset_names:\n",
    "    for model_name in model_names:\n",
    "        for prompting_strategy in prompting_strategies:\n",
    "            # print(f\"Analyzing {dataset_name}/{model_name}/{prompting_strategy}...\")\n",
    "            \n",
    "            key = f\"{dataset_name}_{model_name}_{prompting_strategy}\"\n",
    "\n",
    "            if key not in all_results:\n",
    "                continue\n",
    "\n",
    "            current_result = all_results[key]\n",
    "            current_list = [current_result[\"last_bit\"][\"mean\"], current_result[\"middle_bit\"][\"mean\"], current_result[\"first_bit\"][\"mean\"]]\n",
    "            aaa[key] = current_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assume aaa is already defined\n",
    "def parse_key(key):\n",
    "    parts = key.split('_')\n",
    "    task = parts[0]\n",
    "    model = parts[1]\n",
    "    prompting = '_'.join(parts[2:])\n",
    "    return task, model, prompting\n",
    "\n",
    "def get_ranking(values):\n",
    "    return list(np.argsort([-v for v in values]))  # descending\n",
    "\n",
    "# Step 1: Organize groups for each condition\n",
    "groupings = {\n",
    "    'A': defaultdict(list),  # fix model + prompting => vary tasks\n",
    "    'B': defaultdict(list),  # fix task + prompting => vary model\n",
    "    'C': defaultdict(list),  # fix task + model => vary prompting strategy\n",
    "}\n",
    "\n",
    "for key, values in aaa.items():\n",
    "    task, model, prompting = parse_key(key)\n",
    "    groupings['A'][(model)].append((key, values))\n",
    "    groupings['B'][(task)].append((key, values))\n",
    "    groupings['C'][(prompting)].append((key, values))\n",
    "\n",
    "# Step 2: Compute spearmanr\n",
    "def compute_group_stats(group_dict):\n",
    "    all_distances = []\n",
    "    group_count = 0\n",
    "    for group_key, entries in group_dict.items():\n",
    "        if len(entries) < 2:\n",
    "            continue\n",
    "        group_count += 1\n",
    "        # get rankings\n",
    "        rankings = {k: get_ranking(v) for k, v in entries}\n",
    "        keys = list(rankings.keys())\n",
    "        for i, j in combinations(range(len(keys)), 2):\n",
    "            r1, r2 = rankings[keys[i]], rankings[keys[j]]\n",
    "            r, _ = spearmanr(r1, r2)\n",
    "            if r is not None:\n",
    "                all_distances.append(r)  # convert to distance\n",
    "    return group_count, len(all_distances), np.mean(all_distances) if all_distances else None\n",
    "\n",
    "# Step 3: Report\n",
    "for label in ['A', 'B', 'C']:\n",
    "    groups, comparisons, avg_spearmanr = compute_group_stats(groupings[label])\n",
    "    print(f\"Condition {label}:\")\n",
    "    print(f\"  #Groups: {groups}\")\n",
    "    print(f\"  #Pairwise comparisons: {comparisons}\")\n",
    "    print(f\"  Avg spearman correlation coefficient: {avg_spearmanr:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34cd331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Box plot by position\n",
    "if summary_data:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df_summary, x='Position', y='Mean_Consistency')\n",
    "    plt.title('Consistency Distribution by Format Element Position')\n",
    "    plt.xlabel('Format Element Position')\n",
    "    plt.ylabel('Mean Consistency')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualization 2: Heatmap by dataset and model\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Create pivot table for heatmap\n",
    "    for i, position in enumerate([\"first_bit\", \"middle_bit\", \"last_bit\"]):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        \n",
    "        position_data = df_summary[df_summary['Position'] == position]\n",
    "        if not position_data.empty:\n",
    "            pivot_table = position_data.pivot_table(\n",
    "                values='Mean_Consistency', \n",
    "                index='Dataset', \n",
    "                columns='Model', \n",
    "                aggfunc='mean'\n",
    "            )\n",
    "            \n",
    "            sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='viridis')\n",
    "            plt.title(f'{position.replace(\"_\", \" \").title()} Effect')\n",
    "            plt.xlabel('Model')\n",
    "            plt.ylabel('Dataset')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8492f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Comparison across prompting strategies\n",
    "if summary_data:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    sns.boxplot(data=df_summary, x='Strategy', y='Mean_Consistency', hue='Position')\n",
    "    plt.title('Consistency by Prompting Strategy and Format Element Position')\n",
    "    plt.xlabel('Prompting Strategy')\n",
    "    plt.ylabel('Mean Consistency')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Format Element Position')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa587c5",
   "metadata": {},
   "source": [
    "## 5. Detailed Analysis for Specific Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f126f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed results for interesting cases\n",
    "if all_results:\n",
    "    print(\"Detailed Analysis Examples:\\n\")\n",
    "    \n",
    "    # Find cases with high and low consistency\n",
    "    if summary_data:\n",
    "        df_summary = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Highest consistency case\n",
    "        max_idx = df_summary['Mean_Consistency'].idxmax()\n",
    "        max_case = df_summary.loc[max_idx]\n",
    "        \n",
    "        print(f\"Highest consistency case:\")\n",
    "        print(f\"  {max_case['Dataset']}/{max_case['Model']}/{max_case['Strategy']}\")\n",
    "        print(f\"  Position: {max_case['Position']}, Consistency: {max_case['Mean_Consistency']:.3f}\")\n",
    "        \n",
    "        # Lowest consistency case\n",
    "        min_idx = df_summary['Mean_Consistency'].idxmin()\n",
    "        min_case = df_summary.loc[min_idx]\n",
    "        \n",
    "        print(f\"\\nLowest consistency case:\")\n",
    "        print(f\"  {min_case['Dataset']}/{min_case['Model']}/{min_case['Strategy']}\")\n",
    "        print(f\"  Position: {min_case['Position']}, Consistency: {min_case['Mean_Consistency']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea954e2",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21baf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests to compare positions\n",
    "if summary_data:\n",
    "    from scipy import stats\n",
    "    \n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Group data by position\n",
    "    first_bit_data = df_summary[df_summary['Position'] == 'first_bit']['Mean_Consistency']\n",
    "    middle_bit_data = df_summary[df_summary['Position'] == 'middle_bit']['Mean_Consistency']\n",
    "    last_bit_data = df_summary[df_summary['Position'] == 'last_bit']['Mean_Consistency']\n",
    "    \n",
    "    print(\"Statistical Comparisons (Kruskal-Wallis H-test):\")\n",
    "    \n",
    "    if len(first_bit_data) > 0 and len(middle_bit_data) > 0 and len(last_bit_data) > 0:\n",
    "        # Overall comparison\n",
    "        h_stat, p_value = stats.kruskal(first_bit_data, middle_bit_data, last_bit_data)\n",
    "        print(f\"\\nOverall position comparison:\")\n",
    "        print(f\"  H-statistic: {h_stat:.3f}\")\n",
    "        print(f\"  p-value: {p_value:.3e}\")\n",
    "        \n",
    "        # Pairwise comparisons\n",
    "        comparisons = [\n",
    "            (\"first_bit\", \"middle_bit\", first_bit_data, middle_bit_data),\n",
    "            (\"first_bit\", \"last_bit\", first_bit_data, last_bit_data),\n",
    "            (\"middle_bit\", \"last_bit\", middle_bit_data, last_bit_data)\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nPairwise comparisons (Mann-Whitney U test):\")\n",
    "        for name1, name2, data1, data2 in comparisons:\n",
    "            if len(data1) > 0 and len(data2) > 0:\n",
    "                u_stat, p_val = stats.mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "                print(f\"  {name1} vs {name2}: U={u_stat:.3f}, p={p_val:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33da3b",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec335d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to files\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "if all_results:\n",
    "    # Save detailed results\n",
    "    with open(\"results/single_element_consistency_detailed.json\", \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "if summary_data:\n",
    "    # Save summary CSV\n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    df_summary.to_csv(\"results/single_element_consistency_summary.csv\", index=False)\n",
    "    \n",
    "    # Save position-specific summaries\n",
    "    for position in [\"first_bit\", \"middle_bit\", \"last_bit\"]:\n",
    "        position_data = df_summary[df_summary['Position'] == position]\n",
    "        if not position_data.empty:\n",
    "            position_data.to_csv(f\"results/{position}_consistency_summary.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to 'results/' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda361c6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This analysis measures the consistency between format pairs that differ by exactly one formatting element, allowing us to understand the individual effect of each formatting component on model consistency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
