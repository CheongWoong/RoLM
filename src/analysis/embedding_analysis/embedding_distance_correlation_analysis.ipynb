{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, hamming\n",
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_memmap(filepath):\n",
    "    with open(filepath.replace(\".dat\", \".conf\"), \"r\") as fin_config:\n",
    "        memmap_configs = json.load(fin_config)\n",
    "        return np.memmap(filepath, mode=\"r\", shape=tuple(memmap_configs[\"shape\"]), dtype=memmap_configs[\"dtype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_distance_3bits(a, b):\n",
    "    a = list(f\"{a:03b}\")\n",
    "    b = list(f\"{b:03b}\")\n",
    "    return 3*hamming(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with consistency (best layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"correlation_analysis_table\", exist_ok=True)\n",
    "\n",
    "dataset_names = [\"CommonsenseQA\", \"QASC\", \"100TFQA\", \"GSM8K\", \"MMLU-Pro-Law-100Q\"]\n",
    "model_names = [\"Phi-3.5-mini-instruct\", \"Llama-3.1-8B-Instruct\"]\n",
    "prompting_strategies = [\"zero-shot\", \"zero-shot-cot\", \"few-shot\", \"few-shot-cot\"]\n",
    "\n",
    "NUM_LAYERS = 32\n",
    "corr_matrix, p_matrix = np.zeros((len(model_names), len(dataset_names), len(prompting_strategies), NUM_LAYERS)), np.zeros((len(model_names), len(dataset_names), len(prompting_strategies), NUM_LAYERS))\n",
    "for i, model_name in enumerate(model_names):\n",
    "    for j, dataset_name in enumerate(dataset_names):\n",
    "        for k, prompting_strategy in enumerate(prompting_strategies):\n",
    "            output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "\n",
    "            layer_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_layer_wise_hidden_states.dat\")\n",
    "            head_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_head_wise_hidden_states.dat\")\n",
    "\n",
    "            try:\n",
    "                layer_wise_hidden_states = read_memmap(layer_wise_path)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # corr_matrix[i][j][k] = -2\n",
    "                # p_matrix[i][j][k] = -2\n",
    "                continue\n",
    "            num_samples, num_formats, num_layers, hidden_size = layer_wise_hidden_states.shape\n",
    "\n",
    "            # Prepare pairwise consistency matrix (macro)\n",
    "            score_path = os.path.join(output_dir, f\"{prompting_strategy}_score.json\")\n",
    "            with open(score_path, \"r\") as fin:\n",
    "                score = json.load(fin)\n",
    "            pairwise_consistency_matrix = np.ones((num_formats, num_formats))\n",
    "            for key, value in score[\"consistency\"].items():\n",
    "                if key == \"mean\":\n",
    "                    continue\n",
    "                split_key = key.split(\"_\")\n",
    "                ii, jj = int(split_key[0]), int(split_key[-1])\n",
    "                pairwise_consistency_matrix[ii][jj] = value\n",
    "                pairwise_consistency_matrix[jj][ii] = value\n",
    "\n",
    "            for layer_idx in range(num_layers):\n",
    "                # Step 1: Prepare input\n",
    "                X = layer_wise_hidden_states[:,:,layer_idx,:]\n",
    "                Y = np.tile(np.arange(num_formats), num_samples)\n",
    "                X_mean = X.mean(axis=0)\n",
    "                \n",
    "                # Step 2: Macro analysis\n",
    "                pairwise_distance_list, pairwise_consistency_list = [], []\n",
    "                for ii in range(num_formats):\n",
    "                    for jj in range(num_formats):\n",
    "                        if ii < jj:\n",
    "                            dist = euclidean(X_mean[ii], X_mean[jj])\n",
    "                            pairwise_distance_list.append(dist)\n",
    "                            pairwise_consistency_list.append(pairwise_consistency_matrix[ii][jj])\n",
    "\n",
    "                pearson_corr, pearson_p = pearsonr(pairwise_distance_list, pairwise_consistency_list)\n",
    "                spearman_corr, spearman_p = spearmanr(pairwise_distance_list, pairwise_consistency_list)\n",
    "\n",
    "                # Print correlation results\n",
    "                print(f\"{dataset_name} / {model_name} / {prompting_strategy}\")\n",
    "                print(f\"Layer {layer_idx}\")\n",
    "                print(\"Macro analysis\")\n",
    "                print(f\"Pearson correlation: {pearson_corr:.2f} (p-value: {pearson_p:.3e})\")\n",
    "                print(f\"Spearman correlation: {spearman_corr:.2f} (p-value: {spearman_p:.3e})\")\n",
    "                print()\n",
    "\n",
    "                # if spearman_corr < corr_matrix[i][j][k]:\n",
    "                corr_matrix[i][j][k][layer_idx] = spearman_corr\n",
    "                p_matrix[i][j][k][layer_idx] = spearman_p\n",
    "\n",
    "# prompting_strategies = [\"Zero-shot\", \"Zero-shot CoT\", \"Few-shot\", \"Few-shot CoT\"]\n",
    "# # Create LaTeX table string\n",
    "# latex_code = \"\\\\begin{table}[ht]\\n\"\n",
    "# latex_code += \"\\\\centering\\n\"\n",
    "# latex_code += \"\\\\caption{Correlation analysis between best layer embedding distance and pairwise consistency. A layer in which the correlation is maximized is selected as the best layer. Each cell represents Spearman correlation coefficient and p-value (in parenthesis).}\\n\"\n",
    "# latex_code += \"\\\\label{tab:best_layer_embedding_distance_correlation}\\n\"\n",
    "# latex_code += \"\\\\begin{tabular}{c|c|cccc}\\n\"\n",
    "# latex_code += \"\\\\toprule\\n\"\n",
    "# latex_code += \"Model & Task & \" + \" & \".join(prompting_strategies) + \" \\\\\\\\\\n\"\n",
    "# latex_code += \"\\\\midrule\\\\midrule\\n\"\n",
    "\n",
    "# # Fill the table with data\n",
    "# for model_idx, model in enumerate(model_names):\n",
    "#     latex_code += f\"\\\\multirow{{4}}{{*}}{{{model}}}\\n\"\n",
    "#     for task_idx, task in enumerate(dataset_names):\n",
    "#         latex_code += \"      \"\n",
    "#         latex_code += f\"& {task} \"\n",
    "#         for strat_idx in range(len(prompting_strategies)):\n",
    "#             corr = corr_matrix[model_idx, task_idx, strat_idx]\n",
    "#             p = p_matrix[model_idx, task_idx, strat_idx]\n",
    "\n",
    "#             # Skip conditions\n",
    "#             if corr < -1.5:\n",
    "#                 latex_code += f\"& - \"\n",
    "#                 continue\n",
    "\n",
    "#             corr_str = f\"{corr:.2f}\"\n",
    "#             p_str = f\"{p:.3e}\" if p < 0.001 else f\"{p:.3f}\"\n",
    "            \n",
    "#             latex_code += f\"& {corr_str} ({p_str}) \"\n",
    "#         latex_code += \"\\\\\\\\\\n\"\n",
    "#     latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "# # Close LaTeX table\n",
    "# latex_code = latex_code.rstrip(\"\\\\midrule\\n\")  # Remove last midrule\n",
    "# latex_code += \"\\\\\\\\\\n\"\n",
    "# latex_code += \"\\\\bottomrule\\n\"\n",
    "# latex_code += \"\\\\end{tabular}\\n\"\n",
    "# latex_code += \"\\\\end{table}\"\n",
    "\n",
    "# # Display the generated LaTeX table code\n",
    "# print(latex_code)\n",
    "\n",
    "# with open(f\"correlation_analysis_table/best_layer_embedding_distance_correlation_with_consistency_table.txt\", \"w\") as fout:\n",
    "#     fout.write(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.makedirs('./embedding_dist_corr_layerwise', exist_ok=True)\n",
    "\n",
    "# 1. 시각화 설정 및 파라미터 정의\n",
    "# 폰트 설정 (깨짐 방지)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 정의된 파라미터들\n",
    "# model_names = ['llama-3.1-8B', 'phi-3.5-mini-instruct']\n",
    "# dataset_names = ['CommonsenseQA', 'GSM8K']\n",
    "# prompting_strategies = ['zero-shot', 'zero-shot-cot', 'few-shot', 'few-shot-cot']\n",
    "num_layers = NUM_LAYERS\n",
    "layers = np.arange(num_layers)\n",
    "\n",
    "# ⭐️ 핵심 변경 사항: 프롬프팅 전략별로 색상 고정\n",
    "color_map = {\n",
    "    'zero-shot': 'tab:blue',\n",
    "    'zero-shot-cot': 'tab:orange',\n",
    "    'few-shot': 'tab:green',\n",
    "    'few-shot-cot': 'tab:red'\n",
    "}\n",
    "\n",
    "# 2. ## 실제 데이터로 교체할 부분 ##\n",
    "# 시연을 위한 임의의 샘플 데이터 생성\n",
    "# 실제 데이터를 이와 같은 딕셔너리 구조로 준비해주세요.\n",
    "correlation_data = corr_matrix\n",
    "\n",
    "print(\"샘플 데이터 구조 (NumPy Array):\")\n",
    "print(f\"전체 데이터 shape: {correlation_data.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# 3. 시각화 및 파일 저장\n",
    "for model_idx, model in enumerate(model_names):\n",
    "    for dataset_idx, dataset in enumerate(dataset_names):\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        has_data = False\n",
    "        \n",
    "        for strategy_idx, strategy in enumerate(prompting_strategies):\n",
    "            correlations = correlation_data[model_idx, dataset_idx, strategy_idx, :]\n",
    "            \n",
    "            if not np.any(correlations):\n",
    "                continue\n",
    "            \n",
    "            has_data = True\n",
    "            \n",
    "            # ⭐️ 핵심 변경 사항: color_map에서 지정된 색상을 사용\n",
    "            plt.plot(layers, correlations, marker='o', linestyle='-', label=strategy, color=color_map[strategy])\n",
    "            \n",
    "        plt.title(f'Model: {model} | Dataset: {dataset}\\nLayer-wise Spearman Correlation', fontsize=16)\n",
    "        plt.xlabel('Layer Number', fontsize=12)\n",
    "        plt.ylabel('Spearman Correlation Coefficient', fontsize=12)\n",
    "        plt.ylim(-1.0, 1.0)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        \n",
    "        if has_data:\n",
    "            plt.legend(title='Prompting Strategy', fontsize=10)\n",
    "            filename = f'embedding_dist_corr_layerwise/{model}_{dataset}_embedding_dist_corr_layerwise.png'\n",
    "            plt.savefig(filename)\n",
    "            print(f\"'{filename}' 파일이 저장되었습니다.\")\n",
    "            # plt.show()\n",
    "        else:\n",
    "            print(f\"WARNING: '{model} | {dataset}' 조합에는 유효한 데이터가 없어 그래프를 저장하지 않습니다.\")\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_corr_matrix = np.zeros((len(model_names), len(dataset_names), len(prompting_strategies), 6))\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    for j in range(len(dataset_names)):\n",
    "        for k in range(len(prompting_strategies)):\n",
    "            agg_corr_matrix[i][j][k][0] = corr_matrix[i][j][k].mean()\n",
    "            agg_corr_matrix[i][j][k][1] = corr_matrix[i][j][k].std()\n",
    "            agg_corr_matrix[i][j][k][2] = corr_matrix[i][j][k].min()\n",
    "            agg_corr_matrix[i][j][k][3] = corr_matrix[i][j][k].max()\n",
    "            agg_corr_matrix[i][j][k][4] = corr_matrix[i][j][k].argmin()\n",
    "            agg_corr_matrix[i][j][k][5] = corr_matrix[i][j][k].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 2. LaTeX 테이블 생성 함수 ---\n",
    "\n",
    "def generate_latex_table(agg_matrix, models, datasets, strategies):\n",
    "    \"\"\"\n",
    "    집계된 데이터 행렬을 바탕으로 LaTeX 테이블 코드를 생성합니다.\n",
    "    \"\"\"\n",
    "    # LaTeX 코드 시작 부분\n",
    "    latex_code = []\n",
    "    latex_code.append(r\"\\begin{table*}[t]\")\n",
    "    latex_code.append(r\"    \\centering\")\n",
    "    latex_code.append(r\"    \\caption{Aggregated Spearman Correlation Statistics by Model, Dataset, and Strategy}\")\n",
    "    latex_code.append(r\"    \\label{tab:agg_stats}\")\n",
    "    latex_code.append(r\"    \\begin{tabular}{lllrrrrr}\")\n",
    "    latex_code.append(r\"        \\toprule\")\n",
    "    latex_code.append(r\"        \\textbf{Model} & \\textbf{Dataset} & \\textbf{Strategy} & \\textbf{Mean Corr.} & \\textbf{Std} & \\textbf{Min Corr.} & \\textbf{Max Corr.} & \\textbf{Best Layer} \\\\\")\n",
    "    latex_code.append(r\"        \\midrule\")\n",
    "\n",
    "    # 데이터 행 추가\n",
    "    num_strategies = len(strategies)\n",
    "    for i, model in enumerate(models):\n",
    "        # 모델별로 구분선 추가 (첫 모델 제외)\n",
    "        if i > 0:\n",
    "            latex_code.append(r\"        \\midrule\")\n",
    "        \n",
    "        num_rows_for_model = len(datasets) * num_strategies\n",
    "        model_str = f\"\\\\multirow{{{num_rows_for_model}}}{{*}}{{{model.replace('_', '-')}}}\"\n",
    "\n",
    "        for j, dataset in enumerate(datasets):\n",
    "            if j > 0:\n",
    "                latex_code.append(r\"        \\cmidrule(l){2-8}\")\n",
    "            \n",
    "            dataset_str = f\"\\\\multirow{{{num_strategies}}}{{*}}{{{dataset}}}\"\n",
    "            \n",
    "            for k, strategy in enumerate(strategies):\n",
    "                stats = agg_matrix[i, j, k]\n",
    "                mean, std, min_c, max_c, best_layer_idx = stats[0], stats[1], stats[2], stats[3], int(stats[4])\n",
    "\n",
    "                row = []\n",
    "                if j == 0 and k == 0: # 모델의 첫 번째 행\n",
    "                    row.append(f\"        {model_str}\")\n",
    "                else:\n",
    "                    row.append(\"        \") # 빈 셀\n",
    "\n",
    "                if k == 0: # 데이터셋의 첫 번째 행\n",
    "                    row.append(f\"{dataset_str}\")\n",
    "                else:\n",
    "                    row.append(\"        \") # 빈 셀\n",
    "                \n",
    "                row.append(f\"{strategy}\")\n",
    "                row.append(f\"{mean:.2f}\")\n",
    "                row.append(f\"{std:.2f}\")\n",
    "                row.append(f\"{min_c:.2f}\")\n",
    "                row.append(f\"{max_c:.2f}\")\n",
    "                row.append(f\"{best_layer_idx}\")\n",
    "                \n",
    "                latex_code.append(\" & \".join(row) + r\" \\\\\")\n",
    "\n",
    "    # LaTeX 코드 끝 부분\n",
    "    latex_code.append(r\"        \\bottomrule\")\n",
    "    latex_code.append(r\"    \\end{tabular}\")\n",
    "    latex_code.append(r\"\\end{table*}\")\n",
    "    \n",
    "    return \"\\n\".join(latex_code)\n",
    "\n",
    "# --- 3. 함수 실행 및 결과 출력 ---\n",
    "latex_output = generate_latex_table(agg_corr_matrix, model_names, dataset_names, prompting_strategies)\n",
    "print(latex_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
