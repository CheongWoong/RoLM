{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_memmap(filepath):\n",
    "    with open(filepath.replace(\".dat\", \".conf\"), \"r\") as fin_config:\n",
    "        memmap_configs = json.load(fin_config)\n",
    "        return np.memmap(filepath, mode=\"r\", shape=tuple(memmap_configs[\"shape\"]), dtype=memmap_configs[\"dtype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FORMATS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\"\n",
    "input_dir = \"../../../preprocessed_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-3.1-8B-Instruct\"\n",
    "dataset_name = \"CommonsenseQA\"\n",
    "prompting_strategy = \"zero-shot\"\n",
    "\n",
    "output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "\n",
    "predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_predictions.jsonl\")\n",
    "raw_predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_raw_predictions.jsonl\")\n",
    "try:\n",
    "    with jsonlines.open(predictions_path) as fin:\n",
    "        id_predictions_map = {}\n",
    "        for example in fin.iter():\n",
    "            id_predictions_map[example[\"id\"]] = example[\"predictions\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "id_majority_level_map = defaultdict(list)\n",
    "with jsonlines.open(raw_predictions_path) as fin:\n",
    "    for example in fin.iter():\n",
    "        id_predictions_map[example[\"id\"]].pop('majority_voting')\n",
    "        for ii in range(NUM_FORMATS):\n",
    "            zz = list(id_predictions_map[example[\"id\"]].values()).count(id_predictions_map[example[\"id\"]][str(ii)])\n",
    "            # print(zz)\n",
    "            # zz = ((zz>7)*1.0) # binarize\n",
    "            # zz = max(8-zz, zz) # pairing\n",
    "            id_majority_level_map[example[\"id\"]].append(zz)\n",
    "        # print()\n",
    "\n",
    "id_majority_level_map = list(id_majority_level_map.values())\n",
    "id_majority_level_map = np.array(id_majority_level_map)\n",
    "\n",
    "id_majority_level_map = id_majority_level_map.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_layer_wise_hidden_states.dat\")\n",
    "head_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_head_wise_hidden_states.dat\")\n",
    "\n",
    "layer_wise_hidden_states = read_memmap(layer_wise_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean embedding vectors for 8 formats (first 5 dimensions)\n",
      "[[-0.1315  -0.4983   0.3645  -0.772   -0.02591]\n",
      " [-0.1427  -0.5137   0.3198  -0.7725  -0.0371 ]\n",
      " [-0.1595  -0.507    0.3645  -0.788   -0.0375 ]\n",
      " [-0.1433  -0.4856   0.3845  -0.793   -0.04163]\n",
      " [-0.1385  -0.4937   0.3862  -0.776   -0.03073]\n",
      " [-0.1332  -0.508    0.3699  -0.7837  -0.0452 ]\n",
      " [-0.1321  -0.5015   0.387   -0.7803  -0.03253]\n",
      " [-0.132   -0.5107   0.378   -0.78    -0.03114]]\n",
      "\n",
      "Pairwise embedding distance (Euclidean)\n",
      "    0.00  118.65  116.02  143.85  118.16  114.65   71.04   88.67\n",
      "  118.65    0.00  115.62  136.82  145.02  119.24  149.80  111.13\n",
      "  116.02  115.62    0.00  105.96   79.00   93.95  119.34   82.28\n",
      "  143.85  136.82  105.96    0.00  122.17  115.62  144.34  100.59\n",
      "  118.16  145.02   79.00  122.17    0.00  103.52  115.23   94.38\n",
      "  114.65  119.24   93.95  115.62  103.52    0.00   90.97   70.61\n",
      "   71.04  149.80  119.34  144.34  115.23   90.97    0.00   77.49\n",
      "   88.67  111.13   82.28  100.59   94.38   70.61   77.49    0.00\n",
      "\n",
      "Linear probing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        26\n",
      "           2       0.19      0.13      0.16        30\n",
      "           3       0.44      0.34      0.39        32\n",
      "           4       0.97      0.86      0.91        35\n",
      "           5       0.52      0.61      0.56        49\n",
      "           6       0.71      0.69      0.70        74\n",
      "           7       0.84      0.89      0.87       153\n",
      "           8       0.99      1.00      1.00      3509\n",
      "\n",
      "    accuracy                           0.96      3908\n",
      "   macro avg       0.58      0.57      0.57      3908\n",
      "weighted avg       0.96      0.96      0.96      3908\n",
      "\n",
      "[[   0    0    0    0    1    0   25    0]\n",
      " [   0    4    0    0    2   21    0    3]\n",
      " [   1    1   11    1   17    0    0    1]\n",
      " [   4    0    0   30    0    0    0    1]\n",
      " [   0    0   13    0   30    0    0    6]\n",
      " [   1   16    1    0    0   51    0    5]\n",
      " [  15    0    0    0    0    0  136    2]\n",
      " [   0    0    0    0    8    0    0 3501]]\n",
      "********************\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "num_samples, num_formats, num_layers, hidden_size = layer_wise_hidden_states.shape\n",
    "for layer_idx in range(num_layers):\n",
    "    if layer_idx not in [31]:\n",
    "        continue\n",
    "\n",
    "    # Step 1: Prepare input\n",
    "    X = layer_wise_hidden_states[:,:,layer_idx,:]\n",
    "    X = X.reshape(-1, hidden_size)\n",
    "    # Y = np.tile(np.arange(num_formats), num_samples)\n",
    "    Y = id_majority_level_map\n",
    "\n",
    "    Xs = []\n",
    "    for zi in range(1, 8+1):\n",
    "        Xs.append(X[Y == zi].mean(0))\n",
    "    Xs = np.array(Xs)\n",
    "    Xsvar = Xs.var(0)\n",
    "    target_idx = np.argsort(Xsvar)[::-1][:5]\n",
    "\n",
    "    print(\"Mean embedding vectors for 8 formats (first 5 dimensions)\")\n",
    "    print(Xs[:,:5])\n",
    "    print()\n",
    "\n",
    "    print(\"Pairwise embedding distance (Euclidean)\")\n",
    "    for ii in range(8):\n",
    "        for jj in range(8):\n",
    "            # print(f\"{distance.cosine(Xs[ii], Xs[jj])*100:2.2f}\", end=' ')\n",
    "            print(f\"{distance.euclidean(Xs[ii], Xs[jj])*100:8.2f}\", end='')\n",
    "        print()\n",
    "    print()\n",
    "\n",
    "    print(\"Linear probing\")\n",
    "    # Step 2: Train-test split (2-fold)\n",
    "    X_fold1, X_fold2, y_fold1, y_fold2 = train_test_split(X, Y, test_size=0.5, random_state=0)\n",
    "\n",
    "    layer_accuracy_scores = []\n",
    "    for i in range(2):\n",
    "        # Step 3: Standardization\n",
    "        scaler = StandardScaler()\n",
    "        if i == 0:\n",
    "            X_train = scaler.fit_transform(X_fold1)\n",
    "            X_test = scaler.transform(X_fold2)\n",
    "            y_train, y_test = y_fold1, y_fold2\n",
    "        else:\n",
    "            break\n",
    "            X_train = scaler.fit_transform(X_fold2)\n",
    "            X_test = scaler.transform(X_fold1)\n",
    "            y_train, y_test = y_fold2, y_fold1\n",
    "\n",
    "        # Step 4: Train a linear probing model\n",
    "        clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Step 5: Evaluate the model\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        layer_accuracy_scores.append(accuracy)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "    # print(f\"Layer {layer_idx}: {np.mean(layer_accuracy_scores):.4f}\")\n",
    "    print(\"*\"*20)\n",
    "\n",
    "print(\"*\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
