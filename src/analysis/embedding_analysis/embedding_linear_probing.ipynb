{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_memmap(filepath):\n",
    "    with open(filepath.replace(\".dat\", \".conf\"), \"r\") as fin_config:\n",
    "        memmap_configs = json.load(fin_config)\n",
    "        return np.memmap(filepath, mode=\"r\", shape=tuple(memmap_configs[\"shape\"]), dtype=memmap_configs[\"dtype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dim = 4\n",
    "\n",
    "for dataset_name in [\"100TFQA\", \"CommonsenseQA\", \"QASC\", \"GSM8K\"]:\n",
    "    for model_name in [\"Llama-3.1-8B-Instruct\", \"Phi-3.5-mini-instruct\"]:\n",
    "        for prompting_strategy in [\"zero-shot\", \"zero-shot-cot\", \"few-shot\", \"few-shot-cot\"]:\n",
    "            output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "            layer_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_layer_wise_hidden_states.dat\")\n",
    "            head_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_head_wise_hidden_states.dat\")\n",
    "\n",
    "            input_dir = \"../../../preprocessed_datasets\"\n",
    "            input_path = os.path.join(input_dir, f\"{dataset_name}_test_4_shot.jsonl\")\n",
    "\n",
    "            try:\n",
    "                layer_wise_hidden_states = read_memmap(layer_wise_path)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            num_samples, num_formats, num_layers, hidden_size = layer_wise_hidden_states.shape\n",
    "            for layer_idx in range(num_layers):\n",
    "                if layer_idx not in [31]:\n",
    "                    continue\n",
    "                # Step 1: Prepare input\n",
    "                X = layer_wise_hidden_states[:,:,layer_idx,:].reshape(-1, hidden_size)\n",
    "                Y = np.tile(np.arange(num_formats), num_samples)\n",
    "\n",
    "                # Step 2: PCA Projection\n",
    "                pca = PCA(n_components=pca_dim)\n",
    "                X_pca = pca.fit_transform(X)\n",
    "                # print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "                # Step 2: Train-test split (2-fold)\n",
    "                X_fold1, X_fold2, y_fold1, y_fold2 = train_test_split(X_pca, Y, test_size=0.5, random_state=0)\n",
    "\n",
    "                layer_accuracy_scores = []\n",
    "                for i in range(2):\n",
    "                    # Step 3: Standardization\n",
    "                    scaler = StandardScaler()\n",
    "                    if i == 0:\n",
    "                        X_train = scaler.fit_transform(X_fold1)\n",
    "                        X_test = scaler.transform(X_fold2)\n",
    "                        y_train, y_test = y_fold1, y_fold2\n",
    "                    else:\n",
    "                        X_train = scaler.fit_transform(X_fold2)\n",
    "                        X_test = scaler.transform(X_fold1)\n",
    "                        y_train, y_test = y_fold2, y_fold1\n",
    "\n",
    "                    # Step 4: Train a linear probing model\n",
    "                    clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "                    clf.fit(X_train, y_train)\n",
    "\n",
    "                    # Step 5: Evaluate the model\n",
    "                    y_pred = clf.predict(X_test)\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    layer_accuracy_scores.append(accuracy)\n",
    "                    # print(classification_report(y_test, y_pred))\n",
    "                    # print(confusion_matrix(y_test, y_pred))\n",
    "                print(f\"Layer {layer_idx}: {np.mean(layer_accuracy_scores):.4f}\")\n",
    "                print(f\"{dataset_name} / {model_name} / {prompting_strategy} (above)\")\n",
    "                print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
