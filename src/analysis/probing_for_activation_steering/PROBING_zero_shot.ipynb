{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "\n",
    "from itertools import combinations\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_memmap(filepath):\n",
    "    with open(filepath.replace(\".dat\", \".conf\"), \"r\") as fin_config:\n",
    "        memmap_configs = json.load(fin_config)\n",
    "        return np.memmap(filepath, mode=\"r\", shape=tuple(memmap_configs[\"shape\"]), dtype=memmap_configs[\"dtype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FORMATS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\"\n",
    "input_dir = \"../../../preprocessed_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-3.1-8B-Instruct\"\n",
    "dataset_name = \"CommonsenseQA\"\n",
    "prompting_strategy = \"zero-shot\"\n",
    "\n",
    "output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "\n",
    "predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_predictions_validation.jsonl\")\n",
    "try:\n",
    "    with jsonlines.open(predictions_path) as fin:\n",
    "        id_predictions_map = {}\n",
    "        for example in fin.iter():\n",
    "            id_predictions_map[example[\"id\"]] = example[\"predictions\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "labels = []\n",
    "for preds in id_predictions_map.values():\n",
    "    pairwise_labels = []\n",
    "    for i, j in list(combinations(range(8), 2)):\n",
    "        label = int(preds[str(i)] == preds[str(j)])\n",
    "        pairwise_labels.append(label)\n",
    "    labels.append(pairwise_labels)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_pairwise_embeddings(hidden_states):\n",
    "    num_samples = hidden_states.shape[0]\n",
    "\n",
    "    pairwise_embeddings = []\n",
    "\n",
    "    for s in range(num_samples):\n",
    "        sample_pairs = []\n",
    "        for i, j in list(combinations(range(8), 2)):\n",
    "            emb_i = hidden_states[s, i]\n",
    "            emb_j = hidden_states[s, j]\n",
    "            concat = np.concatenate([emb_i, emb_j], axis=-1)\n",
    "            sample_pairs.append(concat)\n",
    "        sample_pairs = np.stack(sample_pairs, axis=0)\n",
    "        pairwise_embeddings.append(sample_pairs)\n",
    "\n",
    "    return np.stack(pairwise_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_layer_wise_hidden_states_validation.dat\")\n",
    "head_wise_path = os.path.join(output_dir, f\"{prompting_strategy}_head_wise_hidden_states_validation.dat\")\n",
    "\n",
    "layer_wise_hidden_states = read_memmap(layer_wise_path)\n",
    "head_wise_hidden_states = read_memmap(head_wise_path)\n",
    "\n",
    "pairwise_layer_wise_hidden_states = expand_pairwise_embeddings(layer_wise_hidden_states)\n",
    "pairwise_head_wise_hidden_states = expand_pairwise_embeddings(head_wise_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_formats, num_layers, hidden_size = layer_wise_hidden_states.shape\n",
    "num_samples, num_formats, num_layers, num_heads, hidden_size2 = head_wise_hidden_states.shape\n",
    "\n",
    "layer_accuracy_scores = []\n",
    "for layer_idx in range(num_layers):\n",
    "    # if layer_idx not in [31]:\n",
    "    #     continue\n",
    "\n",
    "    # Step 1: Prepare input\n",
    "    X = pairwise_layer_wise_hidden_states[:,:,layer_idx,:]\n",
    "    X = X.reshape(-1, hidden_size*2)\n",
    "    Y = labels.reshape(-1)\n",
    "\n",
    "    # Step 2: 80:20 split for validation to select top-K components\n",
    "    X_fold1, X_fold2, y_fold1, y_fold2 = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "    for i in range(2):\n",
    "        # Step 3: Standardization\n",
    "        scaler = StandardScaler()\n",
    "        if i == 0:\n",
    "            X_train = scaler.fit_transform(X_fold1)\n",
    "            X_test = scaler.transform(X_fold2)\n",
    "            y_train, y_test = y_fold1, y_fold2\n",
    "        else:\n",
    "            break\n",
    "            X_train = scaler.fit_transform(X_fold2)\n",
    "            X_test = scaler.transform(X_fold1)\n",
    "            y_train, y_test = y_fold2, y_fold1\n",
    "\n",
    "        # Step 4: Train a linear probing model\n",
    "        clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Step 5: Evaluate the model\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        layer_accuracy_scores.append(accuracy)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "    print(layer_accuracy_scores)\n",
    "    print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(layer_accuracy_scores, reverse=True)[:10])\n",
    "print()\n",
    "print(sorted(layer_accuracy_scores, reverse=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_formats, num_layers, hidden_size = layer_wise_hidden_states.shape\n",
    "num_samples, num_formats, num_layers, num_heads, hidden_size2 = head_wise_hidden_states.shape\n",
    "\n",
    "head_accuracy_scores = defaultdict(list)\n",
    "for layer_idx in range(num_layers):\n",
    "    # if layer_idx not in [31]:\n",
    "    #     continue\n",
    "    for head_idx in range(num_heads):\n",
    "        # Step 1: Prepare input\n",
    "        X = pairwise_head_wise_hidden_states[:,:,layer_idx,head_idx,:]\n",
    "        X = X.reshape(-1, hidden_size2*2)\n",
    "        Y = labels.reshape(-1)\n",
    "\n",
    "        # Step 2: 80:20 split for validation to select top-K components\n",
    "        X_fold1, X_fold2, y_fold1, y_fold2 = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "        for i in range(2):\n",
    "            # Step 3: Standardization\n",
    "            scaler = StandardScaler()\n",
    "            if i == 0:\n",
    "                X_train = scaler.fit_transform(X_fold1)\n",
    "                X_test = scaler.transform(X_fold2)\n",
    "                y_train, y_test = y_fold1, y_fold2\n",
    "            else:\n",
    "                break\n",
    "                X_train = scaler.fit_transform(X_fold2)\n",
    "                X_test = scaler.transform(X_fold1)\n",
    "                y_train, y_test = y_fold2, y_fold1\n",
    "\n",
    "            # Step 4: Train a linear probing model\n",
    "            clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Step 5: Evaluate the model\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "            head_accuracy_scores[layer_idx].append(accuracy)\n",
    "            # print(classification_report(y_test, y_pred))\n",
    "            # print(confusion_matrix(y_test, y_pred))\n",
    "    print(head_accuracy_scores)\n",
    "    print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(np.array(list(head_accuracy_scores.values())).flatten().tolist(), reverse=True)[:10])\n",
    "print()\n",
    "print(sorted(np.array(list(head_accuracy_scores.values())).flatten().tolist(), reverse=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_heads(scores, k=10):\n",
    "    num_layers, num_heads = scores.shape\n",
    "    flat_scores = scores.flatten()\n",
    "    topk_indices = np.argsort(flat_scores)[-k:][::-1]\n",
    "\n",
    "    topk_info = []\n",
    "    for idx in topk_indices:\n",
    "        layer = idx // num_heads\n",
    "        head = idx % num_heads\n",
    "        score = scores[layer, head]\n",
    "        topk_info.append(((int(layer), int(head)), float(score)))\n",
    "\n",
    "    return topk_info\n",
    "\n",
    "aaa = np.array(list(head_accuracy_scores.values()))\n",
    "print(get_topk_heads(aaa, 25))\n",
    "\n",
    "top_k_heads_path = os.path.join(output_dir, f\"{prompting_strategy}_activation_steering_top_k_heads.json\")\n",
    "with open(top_k_heads_path, \"w\") as fout:\n",
    "    json.dump(get_topk_heads(aaa, 25), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_layers(layer_scores, k=10):\n",
    "    topk_indices = np.argsort(layer_scores)[-k:][::-1]\n",
    "    topk_info = [(idx, layer_scores[idx]) for idx in topk_indices]\n",
    "    return topk_info\n",
    "\n",
    "get_topk_layers(layer_accuracy_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Steering Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "for id, predictions in id_predictions_map.items():\n",
    "    if \"majority_voting\" in predictions:\n",
    "        predictions.pop(\"majority_voting\")\n",
    "    zz = []\n",
    "    for ii in range(NUM_FORMATS):\n",
    "        zzz = list(predictions.values()).count(predictions[str(ii)])\n",
    "        zzz = ((zzz>4)*1.0)\n",
    "        zz.append(zzz)\n",
    "    z.append(zz)\n",
    "majority_minority_array = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_embeddings_by_class(embeddings, majority_minority_array):\n",
    "#     N, F, L, H, D = embeddings.shape\n",
    "\n",
    "#     flat_embeddings = embeddings.reshape(N * F, L, H, D)\n",
    "#     flat_labels = majority_minority_array.reshape(N * F)\n",
    "\n",
    "#     positive_embeddings = flat_embeddings[flat_labels > 0.5]\n",
    "#     negative_embeddings = flat_embeddings[flat_labels < 0.5]\n",
    "\n",
    "#     return positive_embeddings, negative_embeddings\n",
    "\n",
    "def extract_embeddings_by_class(embeddings, majority_minority_array):\n",
    "    N, F, L, H, D = embeddings.shape\n",
    "\n",
    "    selection_idx = np.logical_and(majority_minority_array.mean(1) < 1, majority_minority_array.mean(1) > 0)\n",
    "    selected_embeddings = embeddings[selection_idx]\n",
    "    selected_labels = majority_minority_array[selection_idx]\n",
    "\n",
    "    # (1) without balancing\n",
    "    # selected_N = int(selection_idx.sum())\n",
    "    # flat_embeddings = selected_embeddings.reshape(selected_N * F, L, H, D)\n",
    "    # flat_labels = selected_labels.reshape(selected_N * F)\n",
    "    # positive_embeddings = flat_embeddings[flat_labels > 0.5]\n",
    "    # negative_embeddings = flat_embeddings[flat_labels < 0.5]\n",
    "\n",
    "    # (2) balancing\n",
    "    pos_weight = selected_labels/((selected_labels.sum(1))[...,np.newaxis])\n",
    "    neg_weight = (1-selected_labels)/(((1-selected_labels).sum(1))[...,np.newaxis])\n",
    "    positive_embeddings = (selected_embeddings*pos_weight[...,np.newaxis,np.newaxis,np.newaxis]).sum(1)\n",
    "    negative_embeddings = (selected_embeddings*neg_weight[...,np.newaxis,np.newaxis,np.newaxis]).sum(1)\n",
    "\n",
    "    return positive_embeddings, negative_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = extract_embeddings_by_class(head_wise_hidden_states, majority_minority_array)\n",
    "steering_direction = pos.mean(0) - neg.mean(0)\n",
    "\n",
    "steering_direction_path = os.path.join(output_dir, f\"{prompting_strategy}_activation_steering_direction.npy\")\n",
    "np.save(steering_direction_path, steering_direction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
