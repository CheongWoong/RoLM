{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"correlation_analysis_table\", exist_ok=True)\n",
    "\n",
    "dataset_names = [\"CommonsenseQA\", \"QASC\", \"100TFQA\", \"GSM8K\", \"MMLU-Pro-Law-100Q\"]\n",
    "model_names = [\"Llama-3.1-8B-Instruct\", \"gpt-4o-2024-11-20\"]\n",
    "prompting_strategies = [\"zero-shot\", \"zero-shot-cot\", \"few-shot\", \"few-shot-cot\"]\n",
    "num_formats = NUM_FORMATS = 8\n",
    "\n",
    "corr_matrix, p_matrix = np.zeros((len(model_names), len(dataset_names), len(prompting_strategies))), np.zeros((len(model_names), len(dataset_names), len(prompting_strategies)))\n",
    "for i, model_name in enumerate(model_names):\n",
    "    for j, dataset_name in enumerate(dataset_names):\n",
    "        for k, prompting_strategy in enumerate(prompting_strategies):\n",
    "            output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "            predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_predictions.jsonl\")\n",
    "            raw_predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_raw_predictions.jsonl\")\n",
    "            try:\n",
    "                with jsonlines.open(predictions_path) as fin:\n",
    "                    id_predictions_map, id_consistency_map = {}, {}\n",
    "                    for example in fin.iter():\n",
    "                        id_predictions_map[example[\"id\"]] = example[\"predictions\"]\n",
    "                        id_consistency_map[example[\"id\"]] = example[\"consistency\"][\"mean\"]\n",
    "                X, Y, Z = [], [], []\n",
    "                with jsonlines.open(raw_predictions_path) as fin:\n",
    "                    for example in fin.iter():\n",
    "                        confidences = []\n",
    "                        for format_id, top_tokens in example[\"top_tokens\"].items():\n",
    "                            confidence = -1\n",
    "                            for ii, top_tokenss in enumerate(top_tokens[::-1]):\n",
    "                                if top_tokenss[0] == id_predictions_map[example[\"id\"]][format_id]:\n",
    "                                    if \"top_probs\" in example:\n",
    "                                        confidence = example[\"top_probs\"][format_id][-(ii+1)][0]\n",
    "                                    else:\n",
    "                                        confidence = np.exp(example[\"top_logprobs\"][format_id][-(ii+1)][0])\n",
    "                                    confidences.append(confidence)\n",
    "                                    break\n",
    "                        if len(confidences) != 8:\n",
    "                            # print(example[\"top_tokens\"])\n",
    "                            # print(len(confidences))\n",
    "                            pass\n",
    "                            # raise Exception\n",
    "                        else:\n",
    "                            mean_confidence = np.mean(confidences)\n",
    "                            X.append(mean_confidence)\n",
    "                            Y.append(id_consistency_map[example[\"id\"]])\n",
    "                            Z.append(1.0*(id_consistency_map[example[\"id\"]] >= 0.99))\n",
    "                X, Y, Z = np.array(X), np.array(Y), np.array(Z)\n",
    "                Y = Z # set-wise consistency\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                corr_matrix[i][j][k] = -2\n",
    "                p_matrix[i][j][k] = -2\n",
    "                continue\n",
    "\n",
    "            # Compute Pearson and Spearman correlations\n",
    "            pearson_corr, pearson_p = pearsonr(X, Y)\n",
    "            spearman_corr, spearman_p = spearmanr(X, Y)\n",
    "\n",
    "            # Print correlation results\n",
    "            # print(f\"{dataset_name} / {model_name} / {prompting_strategy}\")\n",
    "            # print(len(X), len(Y), len(Z))\n",
    "            # print(f\"Pearson correlation: {pearson_corr:.2f} (p-value: {pearson_p:.3e})\")\n",
    "            # print(f\"Spearman correlation: {spearman_corr:.2f} (p-value: {spearman_p:.3e})\")\n",
    "\n",
    "            corr_matrix[i][j][k] = spearman_corr\n",
    "            p_matrix[i][j][k] = spearman_p\n",
    "\n",
    "prompting_strategies = [\"Zero-shot\", \"Zero-shot CoT\", \"Few-shot\", \"Few-shot CoT\"]\n",
    "# Create LaTeX table string\n",
    "latex_code = \"\\\\begin{table}[ht]\\n\"\n",
    "latex_code += \"\\\\centering\\n\"\n",
    "latex_code += \"\\\\caption{Correlation analysis between model confidence and setwise consistency. Each cell represents pearson correlation coefficient and p-value (in parenthesis) for GPT-4o across different tasks and prompting strategies.}\\n\"\n",
    "latex_code += \"\\\\label{tab:confidence_correlation}\\n\"\n",
    "latex_code += \"\\\\begin{tabular}{c|c|cccc}\\n\"\n",
    "latex_code += \"\\\\toprule\\n\"\n",
    "latex_code += \"Model & Task & \" + \" & \".join(prompting_strategies) + \" \\\\\\\\\\n\"\n",
    "latex_code += \"\\\\midrule\\\\midrule\\n\"\n",
    "\n",
    "# Fill the table with data\n",
    "for model_idx, model in enumerate(model_names):\n",
    "    latex_code += f\"\\\\multirow{{5}}{{*}}{{{model}}}\\n\"\n",
    "    for task_idx, task in enumerate(dataset_names):\n",
    "        latex_code += \"      \"\n",
    "        latex_code += f\"& {task} \"\n",
    "        for strat_idx in range(len(prompting_strategies)):\n",
    "            corr = corr_matrix[model_idx, task_idx, strat_idx]\n",
    "            p = p_matrix[model_idx, task_idx, strat_idx]\n",
    "\n",
    "            # Skip conditions\n",
    "            if corr < -1.5:\n",
    "                latex_code += f\"& - \"\n",
    "                continue\n",
    "\n",
    "            corr_str = f\"{corr:.2f}\"\n",
    "            p_str = f\"{p:.3e}\" if p < 0.001 else f\"{p:.3f}\"\n",
    "            \n",
    "            latex_code += f\"& {corr_str} ({p_str}) \"\n",
    "        latex_code += \"\\\\\\\\\\n\"\n",
    "    latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "# Close LaTeX table\n",
    "latex_code = latex_code.rstrip(\"\\\\midrule\\n\")  # Remove last midrule\n",
    "latex_code += \"\\\\\\\\\\n\"\n",
    "latex_code += \"\\\\bottomrule\\n\"\n",
    "latex_code += \"\\\\end{tabular}\\n\"\n",
    "latex_code += \"\\\\end{table}\"\n",
    "\n",
    "# Display the generated LaTeX table code\n",
    "print(latex_code)\n",
    "\n",
    "# with open(f\"correlation_analysis_table/correlation_with_consistency_table.txt\", \"w\") as fout:\n",
    "#     fout.write(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
