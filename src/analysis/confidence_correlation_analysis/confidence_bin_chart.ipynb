{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"font.size\": 16,  # Increase base font size\n",
    "    \"axes.labelsize\": 18,  # Labels\n",
    "    \"axes.titlesize\": 20,  # Title\n",
    "    \"xtick.labelsize\": 16,  # X-axis tick labels\n",
    "    \"ytick.labelsize\": 16,  # Y-axis tick labels\n",
    "    \"legend.fontsize\": 16  # Legend\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with consistency (bin chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"bin_chart\", exist_ok=True)\n",
    "\n",
    "dataset_names = [\"CommonsenseQA\", \"QASC\", \"100TFQA\", \"GSM8K\"]\n",
    "model_names = [\"Llama-3.1-8B-Instruct\", \"gpt-4o-2024-11-20\"]\n",
    "prompting_strategies = [\"zero-shot\", \"zero-shot-cot\", \"few-shot\", \"few-shot-cot\"]\n",
    "\n",
    "# Read score file\n",
    "scores = {}\n",
    "for model_name in model_names:\n",
    "    for dataset_name in dataset_names:\n",
    "        for prompting_strategy in prompting_strategies:\n",
    "            output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "            predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_predictions.jsonl\")\n",
    "            raw_predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_raw_predictions.jsonl\")\n",
    "            try:\n",
    "                with jsonlines.open(predictions_path) as fin:\n",
    "                    id_predictions_map, id_consistency_map = {}, {}\n",
    "                    for example in fin.iter():\n",
    "                        id_predictions_map[example[\"id\"]] = example[\"predictions\"]\n",
    "                        id_consistency_map[example[\"id\"]] = example[\"consistency\"][\"mean\"]\n",
    "                X, Y, Z = [], [], []\n",
    "                with jsonlines.open(raw_predictions_path) as fin:\n",
    "                    for example in fin.iter():\n",
    "                        confidences = []\n",
    "                        for format_id, top_tokens in example[\"top_tokens\"].items():\n",
    "                            confidence = -1\n",
    "                            for ii, top_tokenss in enumerate(top_tokens[::-1]):\n",
    "                                if top_tokenss[0] == id_predictions_map[example[\"id\"]][format_id]:\n",
    "                                    if \"top_probs\" in example:\n",
    "                                        confidence = example[\"top_probs\"][format_id][-(ii+1)][0]\n",
    "                                    else:\n",
    "                                        confidence = np.exp(example[\"top_logprobs\"][format_id][-(ii+1)][0])\n",
    "                                    confidences.append(confidence)\n",
    "                                    break\n",
    "                        if len(confidences) != 8:\n",
    "                            # print(example[\"top_tokens\"])\n",
    "                            # print(len(confidences))\n",
    "                            pass\n",
    "                            # raise Exception\n",
    "                        else:\n",
    "                            mean_confidence = np.mean(confidences)\n",
    "                            X.append(mean_confidence)\n",
    "                            Y.append(id_consistency_map[example[\"id\"]])\n",
    "                            Z.append(1.0*(id_consistency_map[example[\"id\"]] >= 0.99))\n",
    "                X, Y, Z = np.array(X), np.array(Y), np.array(Z)\n",
    "                Y = Z # set-wise consistency\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                continue\n",
    "\n",
    "            # Define confidence bins\n",
    "            num_bins = 5  # Adjust this for more granularity\n",
    "            bins = np.array([0.0, 0.8, 0.9, 1.0])\n",
    "            bin_labels = [f\"[{bins[i]:.2f}, {bins[i+1]:.2f})\" for i in range(len(bins)-2)] + [f\"[{bins[len(bins)-2]:.2f}, {bins[len(bins)-1]:.2f}]\"]\n",
    "\n",
    "            # Assign each confidence value to a bin\n",
    "            df = pd.DataFrame({\"Confidence\": X, \"Consistency\": Y})\n",
    "            df[\"Bin\"] = pd.cut(df[\"Confidence\"], bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "            # Compute mean consistency for each bin\n",
    "            bin_means = df.groupby(\"Bin\")[\"Consistency\"].mean()\n",
    "            bin_vars = df.groupby(\"Bin\")[\"Consistency\"].var()\n",
    "\n",
    "            # Plot bar chart\n",
    "            fig = plt.figure(figsize=(10, 6))\n",
    "            plt.bar(bin_means.index, bin_means.values, yerr=bin_vars.values, capsize=5, color=\"royalblue\")\n",
    "\n",
    "            # Labels and formatting\n",
    "            plt.xlabel(\"Confidence Bins\")\n",
    "            plt.ylabel(\"Consistency\")\n",
    "            plt.yticks([-0.01, 0.00, 1.00])\n",
    "            plt.ylim(0.0, 1.0)\n",
    "            plt.title(\"Consistency Across Confidence Levels\")\n",
    "            # plt.xticks(rotation=45)\n",
    "            plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"bin_chart/confidence_correlation_{dataset_name}_{model_name}_{prompting_strategy}.pdf\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended analysis with 128 formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"bin_chart\", exist_ok=True)\n",
    "\n",
    "dataset_names = [\"CommonsenseQA\", \"QASC\"]\n",
    "model_names = [\"Llama-3.1-8B-Instruct\"]\n",
    "prompting_strategies = [\"zero-shot\"]\n",
    "\n",
    "# Read score file\n",
    "scores = {}\n",
    "for model_name in model_names:\n",
    "    for dataset_name in dataset_names:\n",
    "        for prompting_strategy in prompting_strategies:\n",
    "            output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "            predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_ext_predictions.jsonl\")\n",
    "            raw_predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_ext_raw_predictions.jsonl\")\n",
    "            try:\n",
    "                with jsonlines.open(predictions_path) as fin:\n",
    "                    id_predictions_map, id_consistency_map = {}, {}\n",
    "                    for example in fin.iter():\n",
    "                        id_predictions_map[example[\"id\"]] = example[\"predictions\"]\n",
    "                        id_consistency_map[example[\"id\"]] = example[\"consistency\"][\"mean\"]\n",
    "                X, Y, Z = [], [], []\n",
    "                with jsonlines.open(raw_predictions_path) as fin:\n",
    "                    for example in fin.iter():\n",
    "                        confidences = []\n",
    "                        for format_id, top_tokens in example[\"top_tokens\"].items():\n",
    "                            confidence = -1\n",
    "                            for ii, top_tokenss in enumerate(top_tokens[::-1]):\n",
    "                                if top_tokenss[0] == id_predictions_map[example[\"id\"]][format_id]:\n",
    "                                    if \"top_probs\" in example:\n",
    "                                        confidence = example[\"top_probs\"][format_id][-(ii+1)][0]\n",
    "                                    else:\n",
    "                                        confidence = np.exp(example[\"top_logprobs\"][format_id][-(ii+1)][0])\n",
    "                                    confidences.append(confidence)\n",
    "                                    break\n",
    "                        if len(confidences) != 128:\n",
    "                            # print(example[\"top_tokens\"])\n",
    "                            # print(len(confidences))\n",
    "                            pass\n",
    "                            # raise Exception\n",
    "                        else:\n",
    "                            mean_confidence = np.mean(confidences)\n",
    "                            X.append(mean_confidence)\n",
    "                            Y.append(id_consistency_map[example[\"id\"]])\n",
    "                            Z.append(1.0*(id_consistency_map[example[\"id\"]] >= 0.99))\n",
    "                X, Y, Z = np.array(X), np.array(Y), np.array(Z)\n",
    "                Y = Z # set-wise consistency\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                continue\n",
    "\n",
    "            # Define confidence bins\n",
    "            num_bins = 5  # Adjust this for more granularity\n",
    "            bins = np.array([0.0, 0.8, 0.9, 1.0])\n",
    "            bin_labels = [f\"[{bins[i]:.2f}, {bins[i+1]:.2f})\" for i in range(len(bins)-2)] + [f\"[{bins[len(bins)-2]:.2f}, {bins[len(bins)-1]:.2f}]\"]\n",
    "\n",
    "            # Assign each confidence value to a bin\n",
    "            df = pd.DataFrame({\"Confidence\": X, \"Consistency\": Y})\n",
    "            df[\"Bin\"] = pd.cut(df[\"Confidence\"], bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "            # Compute mean consistency for each bin\n",
    "            bin_means = df.groupby(\"Bin\")[\"Consistency\"].mean()\n",
    "            bin_vars = df.groupby(\"Bin\")[\"Consistency\"].var()\n",
    "\n",
    "            # Plot bar chart\n",
    "            fig = plt.figure(figsize=(10, 6))\n",
    "            plt.bar(bin_means.index, bin_means.values, yerr=bin_vars.values, capsize=5, color=\"royalblue\")\n",
    "\n",
    "            # Labels and formatting\n",
    "            plt.xlabel(\"Confidence Bins\")\n",
    "            plt.ylabel(\"Consistency\")\n",
    "            plt.yticks([-0.01, 0.00, 1.00])\n",
    "            plt.ylim(0.0, 1.0)\n",
    "            plt.title(\"Consistency Across Confidence Levels\")\n",
    "            # plt.xticks(rotation=45)\n",
    "            plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"bin_chart/confidence_correlation_{dataset_name}_{model_name}_{prompting_strategy}_EXT.pdf\")\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
