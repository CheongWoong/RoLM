{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../../../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence and majority level (bin count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommonsenseQA / Llama-3.1-8B-Instruct / zero-shot\n",
      "1 /   48 / 0.511\n",
      "2 /   50 / 0.552\n",
      "3 /   69 / 0.576\n",
      "4 /   68 / 0.584\n",
      "5 /   95 / 0.598\n",
      "6 /  144 / 0.638\n",
      "7 /  294 / 0.687\n",
      "8 / 7048 / 0.948\n",
      "\n",
      "CommonsenseQA / Llama-3.1-8B-Instruct / zero-shot-cot\n",
      "1 /  133 / 0.880\n",
      "2 /  158 / 0.862\n",
      "3 /  183 / 0.908\n",
      "4 /  232 / 0.899\n",
      "5 /  315 / 0.903\n",
      "6 /  366 / 0.938\n",
      "7 /  581 / 0.947\n",
      "8 / 5832 / 0.991\n",
      "\n",
      "CommonsenseQA / Llama-3.1-8B-Instruct / few-shot\n",
      "1 /  262 / 0.858\n",
      "2 /  478 / 0.917\n",
      "3 /  165 / 0.776\n",
      "4 /  168 / 0.759\n",
      "5 /  230 / 0.772\n",
      "6 / 1236 / 0.901\n",
      "7 / 1421 / 0.930\n",
      "8 / 3856 / 0.954\n",
      "\n",
      "QASC / Llama-3.1-8B-Instruct / zero-shot\n",
      "1 /   24 / 0.517\n",
      "2 /   50 / 0.492\n",
      "3 /   30 / 0.502\n",
      "4 /   84 / 0.531\n",
      "5 /   60 / 0.583\n",
      "6 /  132 / 0.597\n",
      "7 /  140 / 0.681\n",
      "8 / 5408 / 0.948\n",
      "\n",
      "QASC / Llama-3.1-8B-Instruct / zero-shot-cot\n",
      "1 /   83 / 0.804\n",
      "2 /  104 / 0.851\n",
      "3 /  114 / 0.815\n",
      "4 /   76 / 0.912\n",
      "5 /  180 / 0.938\n",
      "6 /  222 / 0.927\n",
      "7 /  301 / 0.959\n",
      "8 / 4800 / 0.991\n",
      "\n",
      "QASC / Llama-3.1-8B-Instruct / few-shot\n",
      "1 /   83 / 0.750\n",
      "2 /  866 / 0.942\n",
      "3 /  363 / 0.843\n",
      "4 /  456 / 0.846\n",
      "5 /  580 / 0.855\n",
      "6 / 2304 / 0.928\n",
      "7 /  308 / 0.890\n",
      "8 /  968 / 0.922\n",
      "\n",
      "QASC / Llama-3.1-8B-Instruct / few-shot-cot\n",
      "1 /  229 / 0.925\n",
      "2 /  312 / 0.955\n",
      "3 /  396 / 0.954\n",
      "4 /  440 / 0.955\n",
      "5 /  580 / 0.975\n",
      "6 /  756 / 0.983\n",
      "7 / 1071 / 0.991\n",
      "8 / 1528 / 0.982\n",
      "\n",
      "100TFQA / Llama-3.1-8B-Instruct / zero-shot\n",
      "1 /    2 / 0.630\n",
      "2 /    6 / 0.584\n",
      "3 /    3 / 0.768\n",
      "4 /   16 / 0.704\n",
      "5 /    5 / 0.723\n",
      "6 /   18 / 0.680\n",
      "7 /   14 / 0.736\n",
      "8 /  576 / 0.968\n",
      "\n",
      "100TFQA / Llama-3.1-8B-Instruct / zero-shot-cot\n",
      "1 /    4 / 0.791\n",
      "2 /    8 / 0.915\n",
      "3 /   18 / 0.880\n",
      "4 /    8 / 0.938\n",
      "5 /   30 / 0.864\n",
      "6 /   24 / 0.862\n",
      "7 /   28 / 0.865\n",
      "8 /  464 / 0.972\n",
      "\n",
      "100TFQA / Llama-3.1-8B-Instruct / few-shot\n",
      "1 /    2 / 0.633\n",
      "2 /   12 / 0.688\n",
      "3 /   12 / 0.630\n",
      "4 /   56 / 0.684\n",
      "5 /   20 / 0.675\n",
      "6 /   36 / 0.681\n",
      "7 /   14 / 0.758\n",
      "8 /  488 / 0.898\n",
      "\n",
      "100TFQA / Llama-3.1-8B-Instruct / few-shot-cot\n",
      "1 /    6 / 0.731\n",
      "2 /   24 / 0.858\n",
      "3 /   27 / 0.888\n",
      "4 /   40 / 0.915\n",
      "5 /   45 / 0.947\n",
      "6 /   72 / 0.934\n",
      "7 /   42 / 0.977\n",
      "8 /  336 / 0.989\n",
      "\n",
      "GSM8K / Llama-3.1-8B-Instruct / zero-shot-cot\n",
      "1 /  598 / 0.448\n",
      "2 /  516 / 0.524\n",
      "3 /  495 / 0.654\n",
      "4 /  440 / 0.736\n",
      "5 /  480 / 0.770\n",
      "6 /  450 / 0.899\n",
      "7 /  581 / 0.905\n",
      "8 / 1984 / 0.958\n",
      "\n",
      "GSM8K / Llama-3.1-8B-Instruct / few-shot-cot\n",
      "1 /  166 / 0.990\n",
      "2 /  152 / 0.990\n",
      "3 /  135 / 0.999\n",
      "4 /  172 / 0.999\n",
      "5 /  200 / 0.993\n",
      "6 /  252 / 0.999\n",
      "7 /  427 / 0.999\n",
      "8 / 4800 / 0.999\n",
      "\n",
      "CommonsenseQA / gpt-4o-2024-11-20 / zero-shot\n",
      "1 /   28 / 0.649\n",
      "2 /   24 / 0.713\n",
      "3 /   72 / 0.726\n",
      "4 /   68 / 0.711\n",
      "5 /  115 / 0.768\n",
      "6 /   72 / 0.801\n",
      "7 /  189 / 0.833\n",
      "8 / 7248 / 0.992\n",
      "\n",
      "CommonsenseQA / gpt-4o-2024-11-20 / zero-shot-cot\n",
      "1 /   36 / 0.947\n",
      "2 /   52 / 0.988\n",
      "3 /   69 / 0.932\n",
      "4 /   68 / 0.998\n",
      "5 /  110 / 0.992\n",
      "6 /  126 / 0.986\n",
      "7 /  203 / 0.978\n",
      "8 / 7152 / 0.999\n",
      "\n",
      "CommonsenseQA / gpt-4o-2024-11-20 / few-shot\n",
      "1 /   16 / 0.661\n",
      "2 /   18 / 0.649\n",
      "3 /   39 / 0.703\n",
      "4 /   32 / 0.782\n",
      "5 /   70 / 0.820\n",
      "6 /   48 / 0.789\n",
      "7 /  105 / 0.826\n",
      "8 / 7488 / 0.994\n",
      "\n",
      "QASC / gpt-4o-2024-11-20 / zero-shot\n",
      "1 /   15 / 0.697\n",
      "2 /   16 / 0.760\n",
      "3 /   30 / 0.685\n",
      "4 /   40 / 0.744\n",
      "5 /   55 / 0.782\n",
      "6 /   42 / 0.814\n",
      "7 /   98 / 0.844\n",
      "8 / 5632 / 0.992\n",
      "\n",
      "QASC / gpt-4o-2024-11-20 / zero-shot-cot\n",
      "1 /   18 / 0.913\n",
      "2 /   28 / 0.993\n",
      "3 /   39 / 0.903\n",
      "4 /   52 / 0.959\n",
      "5 /   55 / 0.962\n",
      "6 /   54 / 0.997\n",
      "7 /   98 / 0.990\n",
      "8 / 5568 / 1.000\n",
      "\n",
      "QASC / gpt-4o-2024-11-20 / few-shot\n",
      "1 /   13 / 0.673\n",
      "2 /   16 / 0.699\n",
      "3 /   27 / 0.774\n",
      "4 /   12 / 0.862\n",
      "5 /   40 / 0.779\n",
      "6 /   48 / 0.794\n",
      "7 /   84 / 0.825\n",
      "8 / 5688 / 0.995\n",
      "\n",
      "QASC / gpt-4o-2024-11-20 / few-shot-cot\n",
      "1 /   13 / 0.898\n",
      "2 /   16 / 0.999\n",
      "3 /   18 / 0.904\n",
      "4 /   56 / 1.000\n",
      "5 /   15 / 0.850\n",
      "6 /   30 / 1.000\n",
      "7 /   84 / 0.990\n",
      "8 / 5688 / 1.000\n",
      "\n",
      "100TFQA / gpt-4o-2024-11-20 / zero-shot\n",
      "1 /    1 / 0.622\n",
      "2 /    4 / 0.638\n",
      "3 /    3 / 0.840\n",
      "4 /    8 / 0.745\n",
      "5 /    5 / 0.975\n",
      "6 /   12 / 0.824\n",
      "7 /    7 / 0.785\n",
      "8 /  600 / 0.993\n",
      "\n",
      "100TFQA / gpt-4o-2024-11-20 / zero-shot-cot\n",
      "1 /    3 / 1.000\n",
      "2 /    2 / 1.000\n",
      "3 /    0 / nan\n",
      "4 /    0 / nan\n",
      "5 /    0 / nan\n",
      "6 /    6 / 1.000\n",
      "7 /   21 / 1.000\n",
      "8 /  608 / 1.000\n",
      "\n",
      "100TFQA / gpt-4o-2024-11-20 / few-shot\n",
      "1 /    0 / nan\n",
      "2 /    0 / nan\n",
      "3 /    0 / nan\n",
      "4 /    0 / nan\n",
      "5 /    0 / nan\n",
      "6 /    0 / nan\n",
      "7 /    0 / nan\n",
      "8 /  640 / 0.997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/cwkang/anaconda3/envs/RoLM/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/data2/cwkang/anaconda3/envs/RoLM/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100TFQA / gpt-4o-2024-11-20 / few-shot-cot\n",
      "1 /    3 / 1.000\n",
      "2 /    0 / nan\n",
      "3 /    3 / 1.000\n",
      "4 /    0 / nan\n",
      "5 /    5 / 1.000\n",
      "6 /    0 / nan\n",
      "7 /   21 / 1.000\n",
      "8 /  608 / 1.000\n",
      "\n",
      "GSM8K / gpt-4o-2024-11-20 / zero-shot-cot\n",
      "1 /   73 / 0.672\n",
      "2 /   94 / 0.719\n",
      "3 /   81 / 0.782\n",
      "4 /   84 / 0.735\n",
      "5 /  115 / 0.840\n",
      "6 /  132 / 0.977\n",
      "7 /  189 / 0.967\n",
      "8 / 6568 / 0.997\n",
      "\n",
      "GSM8K / gpt-4o-2024-11-20 / few-shot-cot\n",
      "1 /   19 / 0.993\n",
      "2 /   20 / 1.000\n",
      "3 /   30 / 1.000\n",
      "4 /   32 / 1.000\n",
      "5 /   35 / 1.000\n",
      "6 /   60 / 1.000\n",
      "7 /   84 / 1.000\n",
      "8 / 7184 / 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [\"CommonsenseQA\", \"QASC\", \"100TFQA\", \"GSM8K\"]\n",
    "model_names = [\"Llama-3.1-8B-Instruct\", \"gpt-4o-2024-11-20\"]\n",
    "prompting_strategies = [\"zero-shot\", \"zero-shot-cot\", \"few-shot\", \"few-shot-cot\"]\n",
    "\n",
    "# Read score file\n",
    "scores = {}\n",
    "for model_name in model_names:\n",
    "    for dataset_name in dataset_names:\n",
    "        for prompting_strategy in prompting_strategies:\n",
    "            # if dataset_name == \"CommonsenseQA\" and \"gpt\" in model_name and prompting_strategy == \"zero-shot\":\n",
    "            #     pass\n",
    "            # else:\n",
    "            #     continue\n",
    "            dd = defaultdict(list)\n",
    "\n",
    "            output_dir = f\"{result_dir}/{dataset_name}/{model_name}\"\n",
    "            predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_predictions.jsonl\")\n",
    "            raw_predictions_path = os.path.join(output_dir, f\"{prompting_strategy}_raw_predictions.jsonl\")\n",
    "            try:\n",
    "                with jsonlines.open(predictions_path) as fin:\n",
    "                    id_predictions_map, id_consistency_map = {}, {}\n",
    "                    for example in fin.iter():\n",
    "                        id_predictions_map[example[\"id\"]] = example[\"predictions\"]\n",
    "                        id_consistency_map[example[\"id\"]] = example[\"consistency\"][\"mean\"]\n",
    "                X, Y, Z = [], [], []\n",
    "                with jsonlines.open(raw_predictions_path) as fin:\n",
    "                    for example in fin.iter():\n",
    "                        confidences = []\n",
    "                        for format_id, top_tokens in example[\"top_tokens\"].items():\n",
    "                            confidence = -1\n",
    "                            for ii, top_tokenss in enumerate(top_tokens[::-1]):\n",
    "                                if top_tokenss[0] == id_predictions_map[example[\"id\"]][format_id]:\n",
    "                                    if \"top_probs\" in example:\n",
    "                                        confidence = example[\"top_probs\"][format_id][-(ii+1)][0]\n",
    "                                    else:\n",
    "                                        confidence = np.exp(example[\"top_logprobs\"][format_id][-(ii+1)][0])\n",
    "                                    confidences.append(confidence)\n",
    "                                    break\n",
    "                        if len(confidences) != 8:\n",
    "                            # print(example[\"top_tokens\"])\n",
    "                            # print(len(confidences))\n",
    "                            pass\n",
    "                            # raise Exception\n",
    "                        else:\n",
    "                            mean_confidence = np.mean(confidences)\n",
    "                            X.append(mean_confidence)\n",
    "                            Y.append(id_consistency_map[example[\"id\"]])\n",
    "                            Z.append(1.0*(id_consistency_map[example[\"id\"]] >= 0.99))\n",
    "\n",
    "                            # print(confidences)\n",
    "                            # print()\n",
    "                            id_predictions_map[example[\"id\"]].pop('majority_voting')\n",
    "                            # print(id_predictions_map[example[\"id\"]])\n",
    "\n",
    "                            for ii in range(8):\n",
    "                                zz = list(id_predictions_map[example[\"id\"]].values()).count(id_predictions_map[example[\"id\"]][str(ii)])\n",
    "                                dd[zz].append(confidences[ii])\n",
    "                print(f\"{dataset_name} / {model_name} / {prompting_strategy}\")\n",
    "                for zz in range(1, 9):\n",
    "                    print(f\"{zz} / {len(dd[zz]):4} / {np.mean(dd[zz]):.3f}\")\n",
    "                print()\n",
    "            except:\n",
    "                continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
